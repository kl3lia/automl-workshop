{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#authentication\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ia = InteractiveLoginAuthentication(tenant_id='16b3c013-d300-468d-ac64-7eda0820b6d3')\r\n",
        "\r\n",
        "# You can find tenant id under azure active directory->properties\r\n",
        "ws = Workspace.get(name='Prod',\r\n",
        "                     subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873',\r\n",
        "                     resource_group='ProdRG',auth=ia)"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1666026297467
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ** Create Tabular Dataset from WEB URL (CSV files) and Use Unregistered Dataset Directly in Training Script**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates an unregistered TabularDataset from a WEB URL.\r\n",
        "\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "web_path ='https://dprepdata.blob.core.windows.net/demo/Titanic.csv'\r\n",
        "titanic_ds = Dataset.Tabular.from_delimited_files(path=web_path)\r\n",
        "titanic_ds.take(3).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500  None        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250  None        S  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666026345514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set data schema\r\n",
        "#when you create a TabularDataset, column data types are inferred automatically. \r\n",
        "#If the inferred types don't match your expectations, you can update your dataset schema by specifying column types \r\n",
        "\r\n",
        "from azureml.data.dataset_factory import DataType\r\n",
        "\r\n",
        "titanic_ds = Dataset.Tabular.from_delimited_files(path=web_path, set_column_types={'Survived': DataType.to_bool()})\r\n",
        "\r\n",
        "# preview the first 3 rows of titanic_ds\r\n",
        "titanic_ds.take(3).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1     False       3   \n1            2      True       1   \n2            3      True       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500  None        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250  None        S  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>False</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>True</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666026409328
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''import os\r\n",
        "# Create a folder for the script files\r\n",
        "script_folder = 'workshop_examples'\r\n",
        "os.makedirs(script_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(script_folder)'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\r\n",
        "%%writefile $script_folder/train_titanic.py\r\n",
        "#access data in training script\r\n",
        "\r\n",
        "import argparse\r\n",
        "from azureml.core import Dataset, Run\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str)\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "run = Run.get_context()\r\n",
        "ws = run.experiment.workspace\r\n",
        "\r\n",
        "# get the input dataset by ID\r\n",
        "dataset = Dataset.get_by_id(ws, id=args.input_data)\r\n",
        "\r\n",
        "# load the TabularDataset to pandas DataFrame\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\r\n",
        "# define compute target, add the code\r\n",
        "# define environment as myenv., add the code\r\n",
        "from azureml.core import ScriptRunConfig\r\n",
        "\r\n",
        "src = ScriptRunConfig(source_directory=script_folder,\r\n",
        "                      script='train_titanic.py',\r\n",
        "                      # pass dataset as an input with friendly name 'titanic'\r\n",
        "                      arguments=['--input-data', titanic_ds.as_named_input('titanic')],# titanic_ds is given without registering as a dataset.\r\n",
        "                      compute_target=compute_target,\r\n",
        "                      environment=myenv)\r\n",
        "                             \r\n",
        "# Submit the run configuration for your training run\r\n",
        "run = experiment.submit(src)\r\n",
        "run.wait_for_completion(show_output=True)\r\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tabular Dataset from Datastore (PARQUET files) and Register"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates an unregistered TabularDataset from a DATASTORE  + PARQUET \r\n",
        "\r\n",
        "from azureml.core import Workspace, Datastore, Dataset\r\n",
        "\r\n",
        "datastore_name = ws.get_default_datastore()\r\n",
        "weather_ds = 'centrica-forecasting-dataset'\r\n",
        "\r\n",
        "#load data to blob storage from local folder (weather-data) to be able to create a dataset\r\n",
        "datastore_name.upload('weather_data', weather_ds, overwrite=True, show_progress=True)\r\n",
        "\r\n",
        "datastore_path = [(datastore_name, weather_ds + '/*/*/data.parquet')]\r\n",
        "dataset        = Dataset.Tabular.from_parquet_files(path=datastore_path, partition_format = weather_ds + '/{partition_time:yyyy/MM}/data.parquet')\r\n",
        "# **** To read files in .csv or .tsv format, use  from_delimited_files() method. *****\r\n",
        "#dataset= Dataset.Tabular.from_delimited_files(path=datastore_path)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 12 files\nUploading weather_data/2019/01/.amlignore\nUploaded weather_data/2019/01/.amlignore, 1 files out of an estimated total of 12\nUploading weather_data/2019/01/.amlignore.amltmp\nUploaded weather_data/2019/01/.amlignore.amltmp, 2 files out of an estimated total of 12\nUploading weather_data/2019/01/data.parquet\nUploaded weather_data/2019/01/data.parquet, 3 files out of an estimated total of 12\nUploading weather_data/2019/02/data.parquet\nUploaded weather_data/2019/02/data.parquet, 4 files out of an estimated total of 12\nUploading weather_data/2019/03/data.parquet\nUploaded weather_data/2019/03/data.parquet, 5 files out of an estimated total of 12\nUploading weather_data/2019/04/data.parquet\nUploaded weather_data/2019/04/data.parquet, 6 files out of an estimated total of 12\nUploading weather_data/2019/05/data.parquet\nUploaded weather_data/2019/05/data.parquet, 7 files out of an estimated total of 12\nUploading weather_data/2019/06/data.parquet\nUploaded weather_data/2019/06/data.parquet, 8 files out of an estimated total of 12\nUploading weather_data/2019/07/data.parquet\nUploaded weather_data/2019/07/data.parquet, 9 files out of an estimated total of 12\nUploading weather_data/2019/08/data.parquet\nUploaded weather_data/2019/08/data.parquet, 10 files out of an estimated total of 12\nUploading weather_data/2019/09/data.parquet\nUploaded weather_data/2019/09/data.parquet, 11 files out of an estimated total of 12\nUploading weather_data/2019/10/data.parquet\nUploaded weather_data/2019/10/data.parquet, 12 files out of an estimated total of 12\nUploaded 12 files\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666027959307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_pandas_dataframe().head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "     usaf   wban            datetime  latitude  longitude  elevation  \\\n0  720735  73805 2019-01-01 00:00:00    30.349    -85.788       21.0   \n1  720735  73805 2019-01-01 00:39:00    30.349    -85.788       21.0   \n2  720735  73805 2019-01-01 00:53:00    30.349    -85.788       21.0   \n3  720735  73805 2019-01-01 01:01:00    30.349    -85.788       21.0   \n4  720735  73805 2019-01-01 01:53:00    30.349    -85.788       21.0   \n\n   windAngle  windSpeed  temperature  seaLvlPressure  ... precipDepth  \\\n0      140.0        5.1         21.1             NaN  ...         NaN   \n1      150.0        5.7         21.1             NaN  ...         NaN   \n2      150.0        4.6         21.1          1019.5  ...         0.0   \n3      150.0        4.6         21.1             NaN  ...         NaN   \n4      140.0        4.1         21.1          1019.6  ...         0.0   \n\n   snowDepth                          stationName  countryOrRegion  \\\n0        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n1        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n2        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n3        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n4        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n\n            p_k  year day version __index_level_0__  partition_time  \n0  720735-73805  2019   1     1.0           2390756      2019-01-01  \n1  720735-73805  2019   1     1.0           2390757      2019-01-01  \n2  720735-73805  2019   1     1.0           2390758      2019-01-01  \n3  720735-73805  2019   1     1.0           2390759      2019-01-01  \n4  720735-73805  2019   1     1.0           2390760      2019-01-01  \n\n[5 rows x 24 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usaf</th>\n      <th>wban</th>\n      <th>datetime</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>windAngle</th>\n      <th>windSpeed</th>\n      <th>temperature</th>\n      <th>seaLvlPressure</th>\n      <th>...</th>\n      <th>precipDepth</th>\n      <th>snowDepth</th>\n      <th>stationName</th>\n      <th>countryOrRegion</th>\n      <th>p_k</th>\n      <th>year</th>\n      <th>day</th>\n      <th>version</th>\n      <th>__index_level_0__</th>\n      <th>partition_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>5.1</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390756</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:39:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>5.7</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390757</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>1019.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390758</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:01:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390759</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>4.1</td>\n      <td>21.1</td>\n      <td>1019.6</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390760</td>\n      <td>2019-01-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666026585701
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrangle Data: Tabular Datasets\r\n",
        "* keep_columns()\r\n",
        "* drop_columns()\r\n",
        "* filter()\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\r\n",
        "tsd=dataset.filter(dataset['datetime']<datetime(2019,1,2))\r\n",
        "#tsd = tsd.time_after(datetime(2019, 1, 1)).time_before(datetime(2019, 1, 10))\r\n",
        "tsd.to_pandas_dataframe().head(5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Method filter: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "     usaf   wban            datetime  latitude  longitude  elevation  \\\n0  720735  73805 2019-01-01 00:00:00    30.349    -85.788       21.0   \n1  720735  73805 2019-01-01 00:39:00    30.349    -85.788       21.0   \n2  720735  73805 2019-01-01 00:53:00    30.349    -85.788       21.0   \n3  720735  73805 2019-01-01 01:01:00    30.349    -85.788       21.0   \n4  720735  73805 2019-01-01 01:53:00    30.349    -85.788       21.0   \n\n   windAngle  windSpeed  temperature  seaLvlPressure  ... precipDepth  \\\n0      140.0        5.1         21.1             NaN  ...         NaN   \n1      150.0        5.7         21.1             NaN  ...         NaN   \n2      150.0        4.6         21.1          1019.5  ...         0.0   \n3      150.0        4.6         21.1             NaN  ...         NaN   \n4      140.0        4.1         21.1          1019.6  ...         0.0   \n\n   snowDepth                          stationName  countryOrRegion  \\\n0        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n1        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n2        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n3        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n4        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n\n            p_k  year day version __index_level_0__  partition_time  \n0  720735-73805  2019   1     1.0           2390756      2019-01-01  \n1  720735-73805  2019   1     1.0           2390757      2019-01-01  \n2  720735-73805  2019   1     1.0           2390758      2019-01-01  \n3  720735-73805  2019   1     1.0           2390759      2019-01-01  \n4  720735-73805  2019   1     1.0           2390760      2019-01-01  \n\n[5 rows x 24 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usaf</th>\n      <th>wban</th>\n      <th>datetime</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>windAngle</th>\n      <th>windSpeed</th>\n      <th>temperature</th>\n      <th>seaLvlPressure</th>\n      <th>...</th>\n      <th>precipDepth</th>\n      <th>snowDepth</th>\n      <th>stationName</th>\n      <th>countryOrRegion</th>\n      <th>p_k</th>\n      <th>year</th>\n      <th>day</th>\n      <th>version</th>\n      <th>__index_level_0__</th>\n      <th>partition_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>5.1</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390756</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:39:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>5.7</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390757</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>1019.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390758</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:01:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390759</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>4.1</td>\n      <td>21.1</td>\n      <td>1019.6</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390760</td>\n      <td>2019-01-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666027403761
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsd2 = tsd.keep_columns(columns=['snowDepth', 'datetime', 'partition_time'], validate=False)\r\n",
        "tsd2.to_pandas_dataframe().tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "               datetime  snowDepth partition_time\n154 2019-01-01 20:00:00        NaN     2019-01-01\n155 2019-01-01 21:00:00        NaN     2019-01-01\n156 2019-01-01 21:00:00        NaN     2019-01-01\n157 2019-01-01 22:00:00        NaN     2019-01-01\n158 2019-01-01 23:00:00        NaN     2019-01-01",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>snowDepth</th>\n      <th>partition_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>154</th>\n      <td>2019-01-01 20:00:00</td>\n      <td>NaN</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>2019-01-01 21:00:00</td>\n      <td>NaN</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>2019-01-01 21:00:00</td>\n      <td>NaN</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>2019-01-01 22:00:00</td>\n      <td>NaN</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>2019-01-01 23:00:00</td>\n      <td>NaN</td>\n      <td>2019-01-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666027409500
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsd2 = tsd.drop_columns(columns=['wban', 'snowDepth'])\r\n",
        "tsd2.take(5).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "     usaf            datetime  latitude  longitude  elevation  windAngle  \\\n0  720735 2019-01-01 00:00:00    30.349    -85.788       21.0      140.0   \n1  720735 2019-01-01 00:39:00    30.349    -85.788       21.0      150.0   \n2  720735 2019-01-01 00:53:00    30.349    -85.788       21.0      150.0   \n3  720735 2019-01-01 01:01:00    30.349    -85.788       21.0      150.0   \n4  720735 2019-01-01 01:53:00    30.349    -85.788       21.0      140.0   \n\n   windSpeed  temperature  seaLvlPressure cloudCoverage  ... precipTime  \\\n0        5.1         21.1             NaN          None  ...        NaN   \n1        5.7         21.1             NaN          None  ...        NaN   \n2        4.6         21.1          1019.5          None  ...        1.0   \n3        4.6         21.1             NaN          None  ...        NaN   \n4        4.1         21.1          1019.6          None  ...        1.0   \n\n  precipDepth                          stationName  countryOrRegion  \\\n0         NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n1         NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n2         0.0  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n3         NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n4         0.0  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n\n            p_k  year day  version  __index_level_0__  partition_time  \n0  720735-73805  2019   1      1.0            2390756      2019-01-01  \n1  720735-73805  2019   1      1.0            2390757      2019-01-01  \n2  720735-73805  2019   1      1.0            2390758      2019-01-01  \n3  720735-73805  2019   1      1.0            2390759      2019-01-01  \n4  720735-73805  2019   1      1.0            2390760      2019-01-01  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usaf</th>\n      <th>datetime</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>windAngle</th>\n      <th>windSpeed</th>\n      <th>temperature</th>\n      <th>seaLvlPressure</th>\n      <th>cloudCoverage</th>\n      <th>...</th>\n      <th>precipTime</th>\n      <th>precipDepth</th>\n      <th>stationName</th>\n      <th>countryOrRegion</th>\n      <th>p_k</th>\n      <th>year</th>\n      <th>day</th>\n      <th>version</th>\n      <th>__index_level_0__</th>\n      <th>partition_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>720735</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>5.1</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390756</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>720735</td>\n      <td>2019-01-01 00:39:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>5.7</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390757</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>720735</td>\n      <td>2019-01-01 00:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>1019.5</td>\n      <td>None</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390758</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>720735</td>\n      <td>2019-01-01 01:01:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390759</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>720735</td>\n      <td>2019-01-01 01:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>4.1</td>\n      <td>21.1</td>\n      <td>1019.6</td>\n      <td>None</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390760</td>\n      <td>2019-01-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666027415380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register Tabular Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can register a new dataset under the same name by creating a new version. A dataset version is a way to bookmark the state of your data so that you can apply a specific version of the dataset for experimentation or future reproduction."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign \"datetime\" column as timestamp and \"partition_time\" from folder path as partition_timestamp \r\n",
        "# for Tabular Dataset to activate Time Series related APIs. The column to be assigned should be a Date type.\r\n",
        "#dataset = dataset.with_timestamp_columns(timestamp='datetime', partition_timestamp='partition_time')\r\n",
        "\r\n",
        "# register dataset to Workspace\r\n",
        "registered_ds = dataset.register(workspace=ws, \r\n",
        "                            name=weather_ds, \r\n",
        "                            create_new_version=True, \r\n",
        "                            description='Data for Tabular Dataset- time-series.', \r\n",
        "                            tags={ 'type': 'TabularDataset' })"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666029532021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_ds.to_pandas_dataframe().head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "     usaf   wban            datetime  latitude  longitude  elevation  \\\n0  720735  73805 2019-01-01 00:00:00    30.349    -85.788       21.0   \n1  720735  73805 2019-01-01 00:39:00    30.349    -85.788       21.0   \n2  720735  73805 2019-01-01 00:53:00    30.349    -85.788       21.0   \n3  720735  73805 2019-01-01 01:01:00    30.349    -85.788       21.0   \n4  720735  73805 2019-01-01 01:53:00    30.349    -85.788       21.0   \n\n   windAngle  windSpeed  temperature  seaLvlPressure  ... precipDepth  \\\n0      140.0        5.1         21.1             NaN  ...         NaN   \n1      150.0        5.7         21.1             NaN  ...         NaN   \n2      150.0        4.6         21.1          1019.5  ...         0.0   \n3      150.0        4.6         21.1             NaN  ...         NaN   \n4      140.0        4.1         21.1          1019.6  ...         0.0   \n\n   snowDepth                          stationName  countryOrRegion  \\\n0        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n1        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n2        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n3        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n4        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n\n            p_k  year day version __index_level_0__  partition_time  \n0  720735-73805  2019   1     1.0           2390756      2019-01-01  \n1  720735-73805  2019   1     1.0           2390757      2019-01-01  \n2  720735-73805  2019   1     1.0           2390758      2019-01-01  \n3  720735-73805  2019   1     1.0           2390759      2019-01-01  \n4  720735-73805  2019   1     1.0           2390760      2019-01-01  \n\n[5 rows x 24 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usaf</th>\n      <th>wban</th>\n      <th>datetime</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>windAngle</th>\n      <th>windSpeed</th>\n      <th>temperature</th>\n      <th>seaLvlPressure</th>\n      <th>...</th>\n      <th>precipDepth</th>\n      <th>snowDepth</th>\n      <th>stationName</th>\n      <th>countryOrRegion</th>\n      <th>p_k</th>\n      <th>year</th>\n      <th>day</th>\n      <th>version</th>\n      <th>__index_level_0__</th>\n      <th>partition_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>5.1</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390756</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:39:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>5.7</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390757</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>1019.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390758</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:01:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390759</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>4.1</td>\n      <td>21.1</td>\n      <td>1019.6</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390760</td>\n      <td>2019-01-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666029545530
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload the Dataset from Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get dataset by dataset name\r\n",
        "tsd = Dataset.get_by_name(ws, name=weather_ds)\r\n",
        "#get_by_id() \r\n",
        "\r\n",
        "tsd.to_pandas_dataframe().head(5)\r\n",
        "#returns the latest version of the dataset"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "     usaf   wban            datetime  latitude  longitude  elevation  \\\n0  720735  73805 2019-01-01 00:00:00    30.349    -85.788       21.0   \n1  720735  73805 2019-01-01 00:39:00    30.349    -85.788       21.0   \n2  720735  73805 2019-01-01 00:53:00    30.349    -85.788       21.0   \n3  720735  73805 2019-01-01 01:01:00    30.349    -85.788       21.0   \n4  720735  73805 2019-01-01 01:53:00    30.349    -85.788       21.0   \n\n   windAngle  windSpeed  temperature  seaLvlPressure  ... precipDepth  \\\n0      140.0        5.1         21.1             NaN  ...         NaN   \n1      150.0        5.7         21.1             NaN  ...         NaN   \n2      150.0        4.6         21.1          1019.5  ...         0.0   \n3      150.0        4.6         21.1             NaN  ...         NaN   \n4      140.0        4.1         21.1          1019.6  ...         0.0   \n\n   snowDepth                          stationName  countryOrRegion  \\\n0        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n1        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n2        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n3        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n4        NaN  NORTHWEST FLORIDA BEACHES INTL ARPT               US   \n\n            p_k  year day version __index_level_0__  partition_time  \n0  720735-73805  2019   1     1.0           2390756      2019-01-01  \n1  720735-73805  2019   1     1.0           2390757      2019-01-01  \n2  720735-73805  2019   1     1.0           2390758      2019-01-01  \n3  720735-73805  2019   1     1.0           2390759      2019-01-01  \n4  720735-73805  2019   1     1.0           2390760      2019-01-01  \n\n[5 rows x 24 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usaf</th>\n      <th>wban</th>\n      <th>datetime</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>windAngle</th>\n      <th>windSpeed</th>\n      <th>temperature</th>\n      <th>seaLvlPressure</th>\n      <th>...</th>\n      <th>precipDepth</th>\n      <th>snowDepth</th>\n      <th>stationName</th>\n      <th>countryOrRegion</th>\n      <th>p_k</th>\n      <th>year</th>\n      <th>day</th>\n      <th>version</th>\n      <th>__index_level_0__</th>\n      <th>partition_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>5.1</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390756</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:39:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>5.7</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390757</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 00:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>1019.5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390758</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:01:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>150.0</td>\n      <td>4.6</td>\n      <td>21.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390759</td>\n      <td>2019-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>720735</td>\n      <td>73805</td>\n      <td>2019-01-01 01:53:00</td>\n      <td>30.349</td>\n      <td>-85.788</td>\n      <td>21.0</td>\n      <td>140.0</td>\n      <td>4.1</td>\n      <td>21.1</td>\n      <td>1019.6</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NORTHWEST FLORIDA BEACHES INTL ARPT</td>\n      <td>US</td>\n      <td>720735-73805</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2390760</td>\n      <td>2019-01-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666029725675
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a dataset from pandas dataframe"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "data = pd.read_csv( \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard.csv\")\r\n",
        "\r\n",
        "training_fraud=data.head(27000)\r\n",
        "training_fraud = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    training_fraud, target=(datastore_name, \"dataset/\"), name=\"centrica_dataset_frompandas\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to dataset//c84044a6-d9b2-4a39-a85b-898106e5875a/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666030477275
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create File Dataset **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use from_files() method to load files in any format and create un registered filedataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Represents a collection of file references in datastores or public URLs to use in Azure Machine Learning.\r\n",
        "\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "web_paths = [\r\n",
        "            'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\r\n",
        "            'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\r\n",
        "            'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\r\n",
        "            'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\r\n",
        "            ]\r\n",
        "\r\n",
        "mnist_ds = Dataset.File.from_files(path = web_paths)\r\n",
        "# when you put datastore path instead of web_paths, you can create dataset from datastore\r\n",
        "mnist_ds.to_path() # list the files"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "['/http%3A/%2Fyann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n '/http%3A/%2Fyann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n '/http%3A/%2Fyann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n '/http%3A/%2Fyann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666030573572
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "mnist_file_dataset = mnist_ds.register(workspace=ws,\r\n",
        "                                        name='mnist_opendataset',\r\n",
        "                                        description='mnist training and test dataset',\r\n",
        "                                        create_new_version=True)"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666030583677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Access registered filedataset by dataset name\r\n",
        "file_ds = Dataset.get_by_name(ws, name='mnist_opendataset')"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666031251347
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in file_ds.to_path():\r\n",
        "    print(file_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/http%3A/%2Fyann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n/http%3A/%2Fyann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n/http%3A/%2Fyann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n/http%3A/%2Fyann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666031253490
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}