{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#authentication\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ia = InteractiveLoginAuthentication(tenant_id='16b3c013-d300-468d-ac64-7eda0820b6d3')\r\n",
        "\r\n",
        "# You can find tenant id under azure active directory->properties\r\n",
        "ws = Workspace.get(name='Prod',\r\n",
        "                     subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873',\r\n",
        "                     resource_group='ProdRG',auth=ia)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1665815806256
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ** Create Tabular Dataset **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates an unregistered TabularDataset from a web url.\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "web_path ='https://dprepdata.blob.core.windows.net/demo/Titanic.csv'\r\n",
        "titanic_ds = Dataset.Tabular.from_delimited_files(path=web_path)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665815854246
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates an unregistered TabularDataset from a data store\r\n",
        "from azureml.core import Workspace, Datastore, Dataset\r\n",
        "\r\n",
        "datastore_name = ws.get_default_datastore()\r\n",
        "weather_ds = 'weather-data-florida'\r\n",
        "\r\n",
        "#load data to blob storage from local folder (weather-data) to be able to create a dataset\r\n",
        "datastore_name.upload('weather-data', weather_ds, overwrite=True, show_progress=True)\r\n",
        "    \r\n",
        "datastore_path = [(datastore_name, weather_ds + '/*/*/data.parquet')]\r\n",
        "dataset        = Dataset.Tabular.from_parquet_files(path=datastore_path, partition_format = weather_ds + '/{partition_time:yyyy/MM}/data.parquet')\r\n",
        "\r\n",
        "#Assign \"datetime\" column as timestamp and \"partition_time\" from folder path as partition_timestamp for Tabular Dataset to activate Time Series related APIs. The column to be assigned should be a Date type.\r\n",
        "tsd = dataset.with_timestamp_columns(timestamp='datetime', partition_timestamp='partition_time')\r\n",
        "\r\n",
        "# register dataset to Workspace\r\n",
        "registered_ds = tsd.register(ws, weather_ds, create_new_version=True, description='Data for Tabular Dataset with time-series trait demo.', tags={ 'type': 'TabularDataset' })\r\n",
        "\r\n",
        "#weather_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example for how to use unregistered dataset in the training script**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''import os\r\n",
        "# Create a folder for the script files\r\n",
        "script_folder = 'workshop_examples'\r\n",
        "os.makedirs(script_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(script_folder)'''"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workshop_examples\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665816985816
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\r\n",
        "%%writefile $script_folder/train_titanic.py\r\n",
        "#access data in training script\r\n",
        "\r\n",
        "import argparse\r\n",
        "from azureml.core import Dataset, Run\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str)\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "run = Run.get_context()\r\n",
        "ws = run.experiment.workspace\r\n",
        "\r\n",
        "# get the input dataset by ID\r\n",
        "dataset = Dataset.get_by_id(ws, id=args.input_data)\r\n",
        "\r\n",
        "# load the TabularDataset to pandas DataFrame\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting workshop_examples/train_titanic.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\r\n",
        "# define compute target, add the code\r\n",
        "# define environment as myenv., add the code\r\n",
        "from azureml.core import ScriptRunConfig\r\n",
        "\r\n",
        "src = ScriptRunConfig(source_directory=script_folder,\r\n",
        "                      script='train_titanic.py',\r\n",
        "                      # pass dataset as an input with friendly name 'titanic'\r\n",
        "                      arguments=['--input-data', titanic_ds.as_named_input('titanic')],\r\n",
        "                      compute_target=compute_target,\r\n",
        "                      environment=myenv)\r\n",
        "                             \r\n",
        "# Submit the run configuration for your training run\r\n",
        "run = experiment.submit(src)\r\n",
        "run.wait_for_completion(show_output=True)\r\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "\"\\nfrom azureml.core import ScriptRunConfig\\n\\nsrc = ScriptRunConfig(source_directory=script_folder,\\n                      script='train_titanic.py',\\n                      # pass dataset as an input with friendly name 'titanic'\\n                      arguments=['--input-data', titanic_ds.as_named_input('titanic')],\\n                      compute_target=compute_target,\\n                      environment=myenv)\\n                             \\n# Submit the run configuration for your training run\\nrun = experiment.submit(src)\\nrun.wait_for_completion(show_output=True)\\n\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665817922909
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create File Dataset **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "web_paths = [\r\n",
        "            'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\r\n",
        "            'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\r\n",
        "            'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\r\n",
        "            'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\r\n",
        "            ]\r\n",
        "\r\n",
        "mnist_ds = Dataset.File.from_files(path = web_paths)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create datasets from datastores**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REGISTER DATASETS"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Register dataset\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "dataset = Dataset.get_by_name(workspace, name='AutoMLE2EPipeline_Classification_train')\r\n",
        "data=dataset.take(100).to_pandas_dataframe()\r\n",
        "\r\n",
        "test = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    data, target=(datastore, \"dataset/\"), name=\"AutoMLE2EPipeline_Classification_test\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Access registered datasets **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'titanic_ds'\r\n",
        "\r\n",
        "# Get a dataset by name\r\n",
        "titanic_ds = Dataset.get_by_name(workspace=workspace, name=dataset_name)\r\n",
        "#returns the latest version of the dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}