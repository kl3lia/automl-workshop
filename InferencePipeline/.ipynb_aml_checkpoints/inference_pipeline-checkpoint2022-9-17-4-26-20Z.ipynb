{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "ws=Workspace.from_config()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-10-17:03:50:08,767 INFO     [workspace.py:291] Found the config file in: /config.json\n2022-10-17:03:50:08,801 INFO     [_universal.py:476] Request URL: 'https://management.azure.com/subscriptions?api-version=REDACTED'\nRequest method: 'GET'\nRequest headers:\n    'Accept': 'application/json'\n    'x-ms-client-request-id': 'cb50381e-4dce-11ed-ab33-a5473f9416ea'\n    'User-Agent': 'azsdk-python-azure-mgmt-resource/21.1.0 Python/3.8.5 (Linux-5.15.0-1017-azure-x86_64-with-glibc2.10)'\n    'Authorization': 'REDACTED'\nNo body was attached to the request\n2022-10-17:03:50:08,858 INFO     [_universal.py:504] Response status: 200\nResponse headers:\n    'Cache-Control': 'no-cache'\n    'Pragma': 'no-cache'\n    'Content-Type': 'application/json; charset=utf-8'\n    'Content-Encoding': 'REDACTED'\n    'Expires': '-1'\n    'Vary': 'REDACTED'\n    'x-ms-ratelimit-remaining-tenant-reads': '11999'\n    'x-ms-request-id': '510a5250-15d4-4c5a-91a2-843ae6975f65'\n    'x-ms-correlation-request-id': 'REDACTED'\n    'x-ms-routing-request-id': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'X-Content-Type-Options': 'REDACTED'\n    'Date': 'Mon, 17 Oct 2022 03:50:08 GMT'\n    'Content-Length': '437'\n"
        }
      ],
      "execution_count": 91,
      "metadata": {
        "gather": {
          "logged": 1665978610105
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_cluster = \"Demo-Compute-Cluster\"\r\n",
        "compute_target = ws.compute_targets[pipeline_cluster]"
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978613878
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "\r\n",
        "curated_env=Environment.get(workspace=ws, name='AzureML-sklearn-1.0-ubuntu20.04-py38-cpu')\r\n",
        "pipeline_run_config=RunConfiguration()\r\n",
        "pipeline_run_config.environment=curated_env"
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978616136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "data = pd.read_csv(\r\n",
        "    \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\r\n",
        ")\r\n",
        "data=data.head(100)"
      ],
      "outputs": [],
      "execution_count": 94,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978621944
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset,Datastore\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "datastore_name= ws.get_default_datastore()\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "inference_data = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "                                                data, \r\n",
        "                                                target=(datastore_name, \"scoring\"), \r\n",
        "                                                name=\"inference_Classification_dataset\",\r\n",
        "                                                description='Data for Inference', \r\n",
        "                                                tags={ 'type': 'TabularDataset' }\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-10-17:03:50:23,926 INFO     [datastore_client.py:991] <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f57ea1b56d0>\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to scoring/761d4351-018f-4c26-9b05-9012f47dc628/\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 95,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978627994
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=inference_data.to_pandas_dataframe()\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 96,
          "data": {
            "text/plain": "   age          job  marital    education  default housing loan    contact  \\\n0   57   technician  married  high.school       no      no  yes   cellular   \n1   55      unknown  married      unknown  unknown     yes   no  telephone   \n2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n3   36       admin.  married  high.school       no      no   no  telephone   \n4   27    housemaid  married  high.school       no     yes   no   cellular   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp_var_rate  \\\n0   may         mon  ...         1    999         1      failure        -1.80   \n1   may         thu  ...         2    999         0  nonexistent         1.10   \n2   may         fri  ...         1    999         1      failure        -1.80   \n3   jun         fri  ...         4    999         0  nonexistent         1.40   \n4   jul         fri  ...         2    999         0  nonexistent         1.40   \n\n   cons_price_idx  cons_conf_idx  euribor3m  nr_employed   y  \n0           92.89         -46.20       1.30      5099.10  no  \n1           93.99         -36.40       4.86      5191.00  no  \n2           92.89         -46.20       1.31      5099.10  no  \n3           94.47         -41.80       4.97      5228.10  no  \n4           93.92         -42.70       4.96      5228.10  no  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp_var_rate</th>\n      <th>cons_price_idx</th>\n      <th>cons_conf_idx</th>\n      <th>euribor3m</th>\n      <th>nr_employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.80</td>\n      <td>92.89</td>\n      <td>-46.20</td>\n      <td>1.30</td>\n      <td>5099.10</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>unknown</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>thu</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.10</td>\n      <td>93.99</td>\n      <td>-36.40</td>\n      <td>4.86</td>\n      <td>5191.00</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.9y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.80</td>\n      <td>92.89</td>\n      <td>-46.20</td>\n      <td>1.31</td>\n      <td>5099.10</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>4</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.40</td>\n      <td>94.47</td>\n      <td>-41.80</td>\n      <td>4.97</td>\n      <td>5228.10</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.40</td>\n      <td>93.92</td>\n      <td>-42.70</td>\n      <td>4.96</td>\n      <td>5228.10</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978631916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "#OutputFileDatasetConfig with giving destination\r\n",
        "output_path = (datastore_name, f\"azureml/classification_inference_prep_output/\")\r\n",
        "prepped_output_path = OutputFileDatasetConfig(destination = output_path)\r\n",
        "\r\n",
        "input_ds = Dataset.get_by_name(ws, 'inference_Classification_dataset')\r\n",
        "\r\n",
        "prep_step=PythonScriptStep(\r\n",
        "    name=\"Prepare Data for Inference\",\r\n",
        "    script_name=\"prepare.py\",\r\n",
        "    source_directory=\"./Scripts\",\r\n",
        "    arguments=[\"--output_path\",prepped_output_path],\r\n",
        "    inputs=[input_ds.as_named_input('inference_Classification_dataset')],\r\n",
        "    compute_target=compute_target,\r\n",
        "    runconfig=pipeline_run_config\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978634542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prepped_inference_data=prepped_output_path.read_delimited_files(\"prepped_inference_data_classification.csv\") # This is the data to be used for scoring"
      ],
      "outputs": [],
      "execution_count": 98,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665978640028
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "output_path = (datastore_name, f\"azureml/classification_scoring_results/\")\r\n",
        "inference_output_path = OutputFileDatasetConfig(destination = output_path)\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory=\"./Scripts\",\r\n",
        "    entry_script=\"score.py\",\r\n",
        "    mini_batch_size=\"5\",\r\n",
        "    error_threshold=10,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    environment=curated_env,\r\n",
        "    compute_target=compute_target,\r\n",
        "    node_count=2)\r\n",
        "\r\n",
        "parallelrun_step = ParallelRunStep(\r\n",
        "    name='batch-scoring',\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    inputs=[prepped_inference_data],\r\n",
        "    output=inference_output_path,\r\n",
        "    arguments=['--model_name','automlmodel'],\r\n",
        "    allow_reuse=False\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 101,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665979606399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, name= \"classification-E2E_Inference_Pipeline\")\r\n",
        "\r\n",
        "pipeline = Pipeline(ws, [prep_step,parallelrun_step])\r\n",
        "\r\n",
        "pipeline_run = experiment.submit(pipeline, show_output=True)\r\n",
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-10-17:04:06:49,458 INFO     [datastore_client.py:991] <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f57ea1b56d0>\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Prepare Data for Inference [9a3f31d4][dbf8fbdf-15f5-4319-be31-a4bbddd365b7], (This step will run and generate new outputs)\nCreated step batch-scoring [5ee1b620][92a71f06-d2b2-465c-b060-a848e675f262], (This step will run and generate new outputs)\nSubmitted PipelineRun 2c87de25-f7af-457d-a873-3e857744f63b\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/2c87de25-f7af-457d-a873-3e857744f63b?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRunId: 2c87de25-f7af-457d-a873-3e857744f63b\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/2c87de25-f7af-457d-a873-3e857744f63b?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 5de92f54-3e82-4616-932d-49adbb27c6a0\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/5de92f54-3e82-4616-932d-49adbb27c6a0?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nStepRun( Prepare Data for Inference ) Status: Running\n\nStepRun(Prepare Data for Inference) Execution Summary\n======================================================\nStepRun( Prepare Data for Inference ) Status: Finished\n{'runId': '5de92f54-3e82-4616-932d-49adbb27c6a0', 'target': 'Demo-Compute-Cluster', 'status': 'Completed', 'startTimeUtc': '2022-10-17T04:13:46.026813Z', 'endTimeUtc': '2022-10-17T04:14:49.159198Z', 'services': {}, 'properties': {'ContentSnapshotId': 'e5e5e930-5ff6-42f9-8ea5-24292ec60b15', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'dbf8fbdf-15f5-4319-be31-a4bbddd365b7', 'azureml.moduleName': 'Prepare Data for Inference', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '9a3f31d4', 'azureml.pipelinerunid': '2c87de25-f7af-457d-a873-3e857744f63b', 'azureml.pipeline': '2c87de25-f7af-457d-a873-3e857744f63b', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '84f5a4cb-482f-406c-ab00-4f8c6aadaa23'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'inference_Classification_dataset', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '6ba67627-cbe6-4db0-9e29-55bec15dff97'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'output_85999100'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'azureml/classification_inference_prep_output/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"6ba67627-cbe6-4db0-9e29-55bec15dff97\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='prod', subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873', resource_group='prodrg')\"\n  }\n}}], 'runDefinition': {'script': 'prepare.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--output_path', 'DatasetOutputConfig:output_85999100'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'Demo-Compute-Cluster', 'dataReferences': {}, 'data': {'inference_Classification_dataset': {'dataLocation': {'dataset': {'id': '84f5a4cb-482f-406c-ab00-4f8c6aadaa23', 'name': None, 'version': '5'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'inference_Classification_dataset', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'output_85999100': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'azureml/classification_inference_prep_output/'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '2c87de25-f7af-457d-a873-3e857744f63b', 'azureml.pipelineRun.moduleNodeId': '9a3f31d4', 'azureml.pipelineRun.outputPortName': 'output_85999100'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AzureML-sklearn-1.0-ubuntu20.04-py38-cpu', 'version': '30', 'assetId': 'azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/30', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': None, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': \"FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220902.v1\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/sklearn-1.0\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.8 pip=21.3.1 -c anaconda -c conda-forge\\n\\n# Prepend path to AzureML conda environment\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\n# Install pip dependencies\\nRUN pip install 'matplotlib~=3.5.0' \\\\\\n                'psutil~=5.8.0' \\\\\\n                'tqdm~=4.62.0' \\\\\\n                'pandas~=1.3.0' \\\\\\n                'scipy~=1.7.0' \\\\\\n                'numpy~=1.21.0' \\\\\\n                'ipykernel~=6.0' \\\\\\n                'azureml-core==1.45.0' \\\\\\n                'azureml-defaults==1.45.0' \\\\\\n                'azureml-mlflow==1.45.0' \\\\\\n                'azureml-telemetry==1.45.0' \\\\\\n                'scikit-learn~=1.0.0'\\n\\n# This is needed for mpi to locate libpython\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\n\", 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/rslex.log.2022-10-17-04': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/logs/azureml/dataprep/0/rslex.log.2022-10-17-04?sv=2019-07-07&sr=b&sig=gecEtb2zj82i9sYz3qZsi7Zc%2FW49pNZZgapNKF4yQf8%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A20%3A34Z&ske=2022-10-18T11%3A30%3A34Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A46Z&se=2022-10-17T12%3A14%3A46Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=lH2GXG2fZCCgEWgfbbBCMzEs2ro%2FlyVlNqwa64Iy%2BqY%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A20%3A34Z&ske=2022-10-18T11%3A30%3A34Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A46Z&se=2022-10-17T12%3A14%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=LhENUNB%2Fed2EKWwoc5JVbZd46CpvWapvjNOqdbpJA3s%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A20%3A34Z&ske=2022-10-18T11%3A30%3A34Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A46Z&se=2022-10-17T12%3A14%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ZGxVArjiwTaPricR2ImdoqaPUPQyNSf8z1W6OkrpdSw%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A20%3A34Z&ske=2022-10-18T11%3A30%3A34Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A46Z&se=2022-10-17T12%3A14%3A46Z&sp=r', 'user_logs/std_log.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=LNQeWezyhvhdIC1vrSWHfcQi83UiYsEHZXlvp9bZCpA%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A20%3A34Z&ske=2022-10-18T11%3A30%3A34Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=aOpvAWKEGlzyOnxDga1%2FI%2FMS7n2hWB%2FcmeYaNnE31bE%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=q3wYi4pM2tOOR7eprl3Mv0uuNoXCx68MzA2i8Pggszs%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/data_capability/rslex.log.2022-10-17-04': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/data_capability/rslex.log.2022-10-17-04?sv=2019-07-07&sr=b&sig=MjTco2tntAUQQKIdfZiK6XM4cXWfN0hqP%2FGAlCpCoYc%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=tcSe725j11TjyiWN6kIsjN51Q5vmHT8Dc%2FvhnZ8kGHw%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=frMj%2BGzTlNYe6NSJXXKCQXi77lwi19gcmDFMoEe6Jqo%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=Z6bHD%2BREWufq3sFwekPm3Rdhc9SwunTiXFodIirN%2Bxg%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=lbOGVX4YyKHnCAZCAwVRSb%2FS%2FkNyBinsvA4T3KYYKPM%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.5de92f54-3e82-4616-932d-49adbb27c6a0/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=kmwtVT%2FJ8KZlAYG2j%2FFTCTp%2BzP5aaD7XWYp17u1DoCg%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T03%3A32%3A45Z&ske=2022-10-18T11%3A42%3A45Z&sks=b&skv=2019-07-07&st=2022-10-17T04%3A04%3A51Z&se=2022-10-17T12%3A14%3A51Z&sp=r'}, 'submittedBy': 'Yeliz Kilinc'}\n\n\n\n\nStepRunId: 5f2d9056-e8b1-4167-bd12-3bff08e79308\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/5f2d9056-e8b1-4167-bd12-3bff08e79308?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nStepRun( batch-scoring ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_2d014f7e2fb2b9cd3e0469aae3b341d8e55dbe7370f2b2024c54df5be3170c7e_d.txt\n========================================================================================================================\n2022-10-17T04:18:26Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=51091 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-10-17T04:18:26Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/mounts/workspaceblobstore -- stdout/stderr: \n2022-10-17T04:18:26Z The vmsize standard_ds12_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-10-17T04:18:26Z Starting output-watcher...\n2022-10-17T04:18:26Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2022-10-17T04:18:26Z Executing 'Copy ACR Details file' on 10.0.0.4\n2022-10-17T04:18:26Z Executing 'Copy ACR Details file' on 10.0.0.6\n2022-10-17T04:18:26Z Copy ACR Details file succeeded on 10.0.0.6. Output: \n>>>   \n>>>   \n\nStreaming azureml-logs/55_azureml-execution-tvmps_096b40fd7f12143c16ad0c041403e7a19c2f13b35a76856ab3692a79a3952afb_d.txt\n========================================================================================================================\n2022-10-17T04:18:26Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=45782 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-10-17T04:18:26Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/mounts/workspaceblobstore -- stdout/stderr: \n2022-10-17T04:18:27Z The vmsize standard_ds12_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-10-17T04:18:27Z Starting output-watcher...\n2022-10-17T04:18:27Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n70: Pulling from azureml/curated/sidecar\nd7bfe07ed847: Already exists\ndcef2ac699a5: Pulling fs layer\n42794fc92dfd: Pulling fs layer\n88af38890981: Pulling fs layer\n13e568c28e4b: Pulling fs layer\n18f510a7158e: Pulling fs layer\n8699f484c7da: Pulling fs layer\na7071d489c78: Pulling fs layer\nfd21b2f1d9b3: Pulling fs layer\nfe7fa5ee3450: Pulling fs layer\n2a563e3f81b0: Pulling fs layer\ndbc80e23976b: Pulling fs layer\n6b5e9388df31: Pulling fs layer\n758a21e0749e: Pulling fs layer\n8f938f45ed8d: Pulling fs layer\n13e568c28e4b: Waiting\n18f510a7158e: Waiting\n8699f484c7da: Waiting\na7071d489c78: Waiting\nfd21b2f1d9b3: Waiting\nfe7fa5ee3450: Waiting\n2a563e3f81b0: Waiting\ndbc80e23976b: Waiting\n6b5e9388df31: Waiting\n758a21e0749e: Waiting\n4166290bcbdf: Pulling fs layer\n76cdfb5ed624: Pulling fs layer\n9148a687a452: Pulling fs layer\n4072ca38e5ac: Pulling fs layer\n2ded670cfa94: Pulling fs layer\n659846794281: Pulling fs layer\n194b3b1881f4: Pulling fs layer\n12f7815c54b8: Pulling fs layer\n8f938f45ed8d: Waiting\n659846794281: Waiting\n4072ca38e5ac: Waiting\n194b3b1881f4: Waiting\n12f7815c54b8: Waiting\n76cdfb5ed624: Waiting\n9148a687a452: Waiting\n4166290bcbdf: Waiting\n88af38890981: Verifying Checksum\n88af38890981: Download complete\n13e568c28e4b: Verifying Checksum\n13e568c28e4b: Download complete\n42794fc92dfd: Verifying Checksum\n42794fc92dfd: Download complete\n8699f484c7da: Download complete\na7071d489c78: Verifying Checksum\na7071d489c78: Download complete\n18f510a7158e: Verifying Checksum\n18f510a7158e: Download complete\nfd21b2f1d9b3: Verifying Checksum\nfd21b2f1d9b3: Download complete\nfe7fa5ee3450: Verifying Checksum\nfe7fa5ee3450: Download complete\ndbc80e23976b: Download complete\n2a563e3f81b0: Verifying Checksum\n2a563e3f81b0: Download complete\ndcef2ac699a5: Verifying Checksum\ndcef2ac699a5: Download complete\n8f938f45ed8d: Verifying Checksum\n8f938f45ed8d: Download complete\n4166290bcbdf: Verifying Checksum\n4166290bcbdf: Download complete\n76cdfb5ed624: Verifying Checksum\n76cdfb5ed624: Download complete\n9148a687a452: Download complete\n4072ca38e5ac: Verifying Checksum\n4072ca38e5ac: Download complete\n2ded670cfa94: Verifying Checksum\n2ded670cfa94: Download complete\n659846794281: Verifying Checksum\n659846794281: Download complete\n194b3b1881f4: Verifying Checksum\n194b3b1881f4: Download complete\n12f7815c54b8: Verifying Checksum\n12f7815c54b8: Download complete\n758a21e0749e: Verifying Checksum\n758a21e0749e: Download complete\n6b5e9388df31: Verifying Checksum\n6b5e9388df31: Download complete\ndcef2ac699a5: Pull complete\n42794fc92dfd: Pull complete\n88af38890981: Pull complete\n13e568c28e4b: Pull complete\n18f510a7158e: Pull complete\n8699f484c7da: Pull complete\na7071d489c78: Pull complete\nfd21b2f1d9b3: Pull complete\nfe7fa5ee3450: Pull complete\n2a563e3f81b0: Pull complete\ndbc80e23976b: Pull complete\n6b5e9388df31: Pull complete\n\nStreaming azureml-logs/65_job_prep-tvmps_2d014f7e2fb2b9cd3e0469aae3b341d8e55dbe7370f2b2024c54df5be3170c7e_d.txt\n===============================================================================================================\n[2022-10-17T04:18:52.511427] Entering job preparation.\n[2022-10-17T04:18:53.242469] Starting job preparation.\n[2022-10-17T04:18:53.242505] Extracting the control code.\n[2022-10-17T04:18:53.242846] Starting extract_project.\n[2022-10-17T04:18:53.242892] Starting to extract zip file.\n[2022-10-17T04:18:53.281922] Finished extracting zip file.\n[2022-10-17T04:18:53.286278] Using urllib.request Python 3.0 or later\n[2022-10-17T04:18:53.286323] Start fetching snapshots.\n[2022-10-17T04:18:53.286360] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 50\n[2022-10-17T04:18:53.630617] Finished fetching snapshot.\n[2022-10-17T04:18:53.630662] Start fetching snapshot.\n\nStreaming azureml-logs/65_job_prep-tvmps_096b40fd7f12143c16ad0c041403e7a19c2f13b35a76856ab3692a79a3952afb_d.txt\n===============================================================================================================\n[2022-10-17T04:18:47.770409] Entering job preparation.\n[2022-10-17T04:18:48.363506] Starting job preparation.\n[2022-10-17T04:18:48.363541] Extracting the control code.\n[2022-10-17T04:18:48.363836] Starting extract_project.\n[2022-10-17T04:18:48.363875] Starting to extract zip file.\n[2022-10-17T04:18:48.382042] Finished extracting zip file.\n[2022-10-17T04:18:48.385488] Using urllib.request Python 3.0 or later\n[2022-10-17T04:18:48.385527] Start fetching snapshots.\n[2022-10-17T04:18:48.385558] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 50\n[2022-10-17T04:18:48.867123] Finished fetching snapshot.\n[2022-10-17T04:18:48.867163] Start fetching snapshot.\n[2022-10-17T04:18:58.935439] Finished fetching snapshot.\n[2022-10-17T04:18:58.935519] Finished fetching snapshots.\n[2022-10-17T04:18:58.935525] Finished extract_project.\n[2022-10-17T04:18:58.935614] Finished fetching and extracting the control code.\n[2022-10-17T04:18:58.942799] Start run_history_prep.\n[2022-10-17T04:18:58.949689] Job preparation is complete.\n[2022-10-17T04:18:58.949835] Entering Data Context Managers in Sidecar\n[2022-10-17T04:18:58.950606] Running Sidecar prep cmd...\n[2022-10-17T04:18:59.316346] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308\n[2022-10-17T04:18:59.317077] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2022-10-17T04:18:59.506] Enter __enter__ of DatasetContextManager\n[2022-10-17T04:18:59.506] SDK version: azureml-core==0.1.0.66253449 azureml-dataprep==4.1.0. Session id: 13b0727a-bd2e-4edc-aaea-1c3236373e3b. Run id: 5f2d9056-e8b1-4167-bd12-3bff08e79308.\n[2022-10-17T04:18:59.506] Processing 'output_233c309a'.\n[2022-10-17T04:18:59.507] Mode: 'mount'.\n[2022-10-17T04:18:59.507] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore'.\n[2022-10-17T04:18:59.742] Mounting output_233c309a to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore\n[2022-10-17T04:18:59.742] Output is not a single file\n[2022-10-17T04:18:59.751] Mounted output_233c309a to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore as folder\n[2022-10-17T04:19:01.205] Mounting output_233c309a to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore.\n[2022-10-17T04:19:04.276] Mounted output_233c309a to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore.\n[2022-10-17T04:19:04.284] Exit __enter__ of DatasetContextManager\nSet OutputDataset output_233c309a's target path to /mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore\n[2022-10-17T04:19:04.287476] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2022-10-17T04:19:04.289876] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'output_233c309a' with value '/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore'.\n[2022-10-17T04:19:04.296938] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZURE_ML_OUTPUT_output_233c309a' with value '/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore'.\n[2022-10-17T04:19:04.297281] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZUREML_SIDECAR_PATHS_TO_BIND' with value '[\"/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore:/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12'.\n[2022-10-17T04:19:04.409778] Ran Sidecar prep cmd.\n[2022-10-17T04:19:04.409880] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\nbash: /azureml-envs/sklearn-1.0/lib/libtinfo.so.6: no version information available (required by bash)\n2022/10/17 04:19:52 Didn't get JobInfoJson from env, now read from file\n2022/10/17 04:19:52 Suceeded read JobInfoJson from file\n2022/10/17 04:19:52 Starting App Insight Logger for task:  runTaskLet\n2022/10/17 04:19:52 Version: 3.0.02105.0008 Branch: master Commit: 50facd9\n2022/10/17 04:19:52 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/info\nbash: /azureml-envs/sklearn-1.0/lib/libtinfo.so.6: no version information available (required by bash)\n2022/10/17 04:19:52 Send process info logs to master server succeeded\n2022/10/17 04:19:52 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n2022/10/17 04:19:52 Send process info logs to master server succeeded\n[2022-10-17T04:19:52.531636] Entering context manager injector.\n[2022-10-17T04:19:53.268915] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.44.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:output_233c309a', '--model_name', 'automlmodel', '--input_ds_0', 'input_f4533e93'])\nScript type = None\n[2022-10-17T04:19:53.273706] Entering Run History Context Manager.\n[2022-10-17T04:19:56.395091] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308\n[2022-10-17T04:19:56.395134] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.44.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZURE_ML_OUTPUT_output_233c309a', '--model_name', 'automlmodel', '--input_ds_0', 'input_f4533e93']\n[2022-10-17T04:19:56.395337] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.44.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore', '--model_name', 'automlmodel', '--input_ds_0', 'input_f4533e93']\n\n2022/10/17 04:19:57 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n\nStreaming azureml-logs/75_job_post-tvmps_096b40fd7f12143c16ad0c041403e7a19c2f13b35a76856ab3692a79a3952afb_d.txt\n===============================================================================================================\n[2022-10-17T04:23:04.672566] Entering job release\n[2022-10-17T04:23:05.412303] job release stage : copy_batchai_cached_logs starting...\n[2022-10-17T04:23:05.412343] job release stage : copy_batchai_cached_logs completed...\n[2022-10-17T04:23:05.412386] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-10-17T04:23:05.412887] Running Sidecar release cmd...\n[2022-10-17T04:23:05.421835] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308\n[2022-10-17T04:23:05.432] Enter __exit__ of DatasetContextManager\n[2022-10-17T04:23:05.432] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore.\n[2022-10-17T04:23:05.445] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/prod/azureml/5f2d9056-e8b1-4167-bd12-3bff08e79308/wd/output_233c309a_workspaceblobstore.\n[2022-10-17T04:23:05.445] Exit __exit__ of DatasetContextManager\n[2022-10-17T04:23:05.445634] Removing absolute paths from host...\n[2022-10-17T04:23:05.445879] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-10-17T04:23:05.533537] Ran Sidecar release cmd.\n\nStepRun(batch-scoring) Execution Summary\n=========================================\nStepRun( batch-scoring ) Status: Failed\n\nWarnings:\nAzureMLCompute job failed.\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\n\tReason: Job failed with non-zero exit Code\nUser program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [102]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(ws, [prep_step,parallelrun_step])\n\u001b[1;32m      8\u001b[0m pipeline_run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(pipeline, show_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:738\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    744\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:831\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_details)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 102,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665980599942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Put sample scoring step for time series'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665947283296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "PipelineWithYTransformations(Pipeline={'memory': None,\n                                       'steps': [('datatransformer',\n                                                  DataTransformer(enable_dnn=False, enable_feature_sweeping=False, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=False, is_onnx_compatible=False, observer=None, task='classification', working_dir='/...\n                                                  PreFittedSoftVotingClassifier(classification_labels=array([0, 1]), estimators=[('34', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=True, with_std=True)), ('lightgbmclassifier', LightGBMClassifier(boosting_type='gbdt', colsample_bytree=0.1, learning_rate=0.03158578947368421, max_bin=140, max_depth=3, min_child_weight=2, min_data_in_leaf=0.027593448275862072, min_split_gain=0.9473684210526315, n_estimators=400, n_jobs=-1, num_leaves=5, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None, reg_alpha=0.15789473684210525, reg_lambda=0.7894736842105263, subsample=0.6931578947368422))], verbose=False)), ('1', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('xgboostclassifier', XGBoostClassifier(n_jobs=0, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, tree_method='auto'))], verbose=False)), ('24', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.7, eta=0.3, gamma=0, max_depth=5, max_leaves=0, n_estimators=100, n_jobs=0, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=1.5625, reg_lambda=2.1875, subsample=0.7, tree_method='auto'))], verbose=False)), ('18', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('lightgbmclassifier', LightGBMClassifier(boosting_type='goss', colsample_bytree=0.5944444444444444, learning_rate=0.026323157894736843, max_bin=310, max_depth=-1, min_child_weight=3, min_data_in_leaf=1e-05, min_split_gain=0.7894736842105263, n_estimators=50, n_jobs=-1, num_leaves=131, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None, reg_alpha=0.3684210526315789, reg_lambda=1, subsample=1))], verbose=False)), ('29', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=True, with_std=False)), ('lightgbmclassifier', LightGBMClassifier(boosting_type='goss', colsample_bytree=0.99, learning_rate=0.0842121052631579, max_bin=360, max_depth=5, min_child_weight=0, min_data_in_leaf=0.09655206896551725, min_split_gain=0.3157894736842105, n_estimators=800, n_jobs=-1, num_leaves=239, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None, reg_alpha=0.3684210526315789, reg_lambda=0.7368421052631579, subsample=1))], verbose=False)), ('53', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.8, eta=0.3, gamma=0, max_depth=8, max_leaves=15, n_estimators=800, n_jobs=0, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=0, reg_lambda=1.25, subsample=0.5, tree_method='auto'))], verbose=False)), ('37', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=True, with_std=False)), ('logisticregression', LogisticRegression(C=6866.488450042998, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='multinomial', n_jobs=-1, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('33', Pipeline(memory=None, steps=[('sparsenormalizer', Normalizer(copy=True, norm='l2')), ('lightgbmclassifier', LightGBMClassifier(boosting_type='goss', colsample_bytree=0.1988888888888889, learning_rate=0.07368684210526316, max_bin=230, max_depth=9, min_child_weight=2, min_data_in_leaf=0.024145517241379314, min_split_gain=0.631578947368421, n_estimators=400, n_jobs=-1, num_leaves=17, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None, reg_alpha=0.3157894736842105, reg_lambda=0.631578947368421, subsample=1))], verbose=False))], flatten_transform=None, weights=[0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.4666666666666667, 0.06666666666666667, 0.13333333333333333]))],\n                                       'verbose': False},\n                             y_transformer={},\n                             y_transformer_name='LabelEncoder')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665667786268
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "batch_pipeline\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $Scripts/scoring.py\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from azureml.core import Model\r\n",
        "import joblib\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    # Runs when the pipeline step is initialized\r\n",
        "    global model\r\n",
        "\r\n",
        "    # load the model\r\n",
        "    model_path = Model.get_model_path('diabetes_model')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "    # This runs for each batch\r\n",
        "    resultList = []\r\n",
        "\r\n",
        "    # process each file in the batch\r\n",
        "    for f in mini_batch:\r\n",
        "        # Read the comma-delimited data into an array\r\n",
        "        data = np.genfromtxt(f, delimiter=',')\r\n",
        "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\r\n",
        "        prediction = model.predict(data.reshape(1, -1))\r\n",
        "        # Append prediction to results\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing batch_pipeline/batch_diabetes.py\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_environment.yml\r\n",
        "name: batch_environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing batch_pipeline/batch_environment.yml\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# Create an Environment for the experiment\r\n",
        "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Configuration ready.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore, Dataset\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "# Set default data store\r\n",
        "ws.set_default_datastore('workspaceblobstore')\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Enumerate all datastores, indicating which is the default\r\n",
        "for ds_name in ws.datastores:\r\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\r\n",
        "\r\n",
        "# Load the diabetes data\r\n",
        "diabetes = pd.read_csv('data/diabetes2.csv')\r\n",
        "#diabetes['BMI']=round(diabetes['BMI'])\r\n",
        "#diabetes['DiabetesPedigree']=round(diabetes['DiabetesPedigree'])\r\n",
        "# Get a 2-item sample of the feature columns (not the diabetic label)\r\n",
        "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=2).values\r\n",
        "print(sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml_globaldatasets - Default = False\nworkspacefilestore - Default = False\nworkspaceworkingdirectory - Default = False\nworkspaceblobstore - Default = True\nworkspaceartifactstore - Default = False\n[[  8  92  93  47  36  21   1  23]\n [  0 171  80  34  23  43   1  21]]\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new register_dataset.py\r\n",
        "import argparse\r\n",
        "from azureml.core import Workspace, Dataset\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    parser = argparse.ArgumentParser(description=\"Register dataset\")\r\n",
        "    parser.add_argument(\"-n\", type=str, help=\"Name of the dataset you want to register\")\r\n",
        "    parser.add_argument(\"-d\", type=str, help=\"Description of the dataset you want to register\")\r\n",
        "    parser.add_argument(\"-t\", type=str, help=\"type of dataset\", default='local')    \r\n",
        "    parser.add_argument(\"-l\", type=str, help=\"local path of the dataset folder\", default='data/')\r\n",
        "    parser.add_argument(\"-p\", type=str, help=\"Path on data store\", default='data/')\r\n",
        "    parser.add_argument(\"-s\", type=str, help=\"Storage url for cloud storage\")\r\n",
        "    return parser.parse_args()\r\n",
        "\r\n",
        "def main():\r\n",
        "    args = parse_args()\r\n",
        "    print(args)\r\n",
        "    ws = Workspace.from_config()\r\n",
        "    if args.t == \"local\":\r\n",
        "        print(\"local data\")\r\n",
        "        datastore = ws.get_default_datastore()\r\n",
        "        datastore.upload(src_dir = args.l, target_path = args.p, overwrite = True, show_progress = True)\r\n",
        "        print(f\"About to register dataset {args.n}\")\r\n",
        "\r\n",
        "        dataset = Dataset.File.from_files(path=[(datastore, args.p)], validate=True)\r\n",
        "        dataset = dataset.register(workspace=ws,name=args.n, description=args.d,create_new_version=True)\r\n",
        "        print(\"Dataset registered\")\r\n",
        "    else:\r\n",
        "        print(\"cloud data\")\r\n",
        "        data_urls = [args.s]\r\n",
        "        dataset = Dataset.File.from_files(data_urls)\r\n",
        "        dataset = dataset.register(workspace=ws,name=args.n, description=args.d,create_new_version=True)\r\n",
        "    \r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
        "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output=True)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step batch-score-diabetes [204064bc][65c039e3-182a-48ee-ba32-6a21f0885367], (This step will run and generate new outputs)\nSubmitted PipelineRun 6ddc4b06-fdef-426d-a46b-bebaf785d187\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/6ddc4b06-fdef-426d-a46b-bebaf785d187?wsid=/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourcegroups/machinelearningexperiments/workspaces/ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRunId: 6ddc4b06-fdef-426d-a46b-bebaf785d187\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/6ddc4b06-fdef-426d-a46b-bebaf785d187?wsid=/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourcegroups/machinelearningexperiments/workspaces/ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 4742184a-632f-4e2e-9332-700dbcb91e5a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/4742184a-632f-4e2e-9332-700dbcb91e5a?wsid=/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourcegroups/machinelearningexperiments/workspaces/ml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nStepRun( batch-score-diabetes ) Status: Running\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2022/09/29 09:40:47 Downloading source code...\n2022/09/29 09:40:48 Finished downloading source code\n2022/09/29 09:40:49 Creating Docker network: acb_default_network, driver: 'bridge'\n2022/09/29 09:40:49 Successfully set up Docker network: acb_default_network\n2022/09/29 09:40:49 Setting up Docker configuration...\n2022/09/29 09:40:49 Successfully set up Docker configuration\n2022/09/29 09:40:49 Logging in to registry: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io\n2022/09/29 09:40:50 Successfully logged into 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io\n2022/09/29 09:40:50 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/09/29 09:40:50 Scanning for dependencies...\n2022/09/29 09:40:51 Successfully scanned dependencies\n2022/09/29 09:40:51 Launching container with name: acb_step_0\nSending build context to Docker daemon  66.56kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6: Pulling from azureml/openmpi4.1.0-ubuntu20.04\nd7bfe07ed847: Already exists\n1a9a51b4af0d: Pulling fs layer\n9d74d44c539e: Pulling fs layer\n829bf1798a9e: Pulling fs layer\n5fe57cb5a06b: Pulling fs layer\n0b73c9d3e4c7: Pulling fs layer\ndf3a1ae83fc1: Pulling fs layer\n622a938b5eec: Pulling fs layer\n9d0e20c4f643: Pulling fs layer\ne63d29d12ed0: Pulling fs layer\n5fe57cb5a06b: Waiting\n0b73c9d3e4c7: Waiting\ndf3a1ae83fc1: Waiting\n622a938b5eec: Waiting\n9d0e20c4f643: Waiting\ne63d29d12ed0: Waiting\n829bf1798a9e: Verifying Checksum\n829bf1798a9e: Download complete\n5fe57cb5a06b: Verifying Checksum\n5fe57cb5a06b: Download complete\n9d74d44c539e: Verifying Checksum\n9d74d44c539e: Download complete\ndf3a1ae83fc1: Download complete\n0b73c9d3e4c7: Verifying Checksum\n0b73c9d3e4c7: Download complete\n622a938b5eec: Verifying Checksum\n622a938b5eec: Download complete\n9d0e20c4f643: Verifying Checksum\n9d0e20c4f643: Download complete\ne63d29d12ed0: Verifying Checksum\ne63d29d12ed0: Download complete\n1a9a51b4af0d: Verifying Checksum\n1a9a51b4af0d: Download complete\n1a9a51b4af0d: Pull complete\n9d74d44c539e: Pull complete\n829bf1798a9e: Pull complete\n5fe57cb5a06b: Pull complete\n0b73c9d3e4c7: Pull complete\ndf3a1ae83fc1: Pull complete\n622a938b5eec: Pull complete\n9d0e20c4f643: Pull complete\ne63d29d12ed0: Pull complete\nDigest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n ---> a126cf3d80b0\nStep 2/21 : USER root\n ---> Running in 5821e8f7d772\nRemoving intermediate container 5821e8f7d772\n ---> 926154c8c616\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in 7a030c0dcc3b\nRemoving intermediate container 7a030c0dcc3b\n ---> 52ad3a09d11e\nStep 4/21 : WORKDIR /\n ---> Running in 46ce411d1633\nRemoving intermediate container 46ce411d1633\n ---> fdba71629637\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> d256e0c527ab\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in 08f3e806d423\nRemoving intermediate container 08f3e806d423\n ---> 19efb9dc67a1\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 2666f6f33cea\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 1333d3dd3835\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\ntk-8.6.12            | 3.0 MB    |            |   0% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n\nmkl-2020.2           | 138.3 MB  |            |   0% \nmkl-2020.2           | 138.3 MB  | 8          |   9% \nmkl-2020.2           | 138.3 MB  | #9         |  19% \nmkl-2020.2           | 138.3 MB  | ##8        |  29% \nmkl-2020.2           | 138.3 MB  | ###8       |  38% \nmkl-2020.2           | 138.3 MB  | ####7      |  47% \nmkl-2020.2           | 138.3 MB  | #####5     |  56% \nmkl-2020.2           | 138.3 MB  | ######5    |  65% \nmkl-2020.2           | 138.3 MB  | #######4   |  74% \nmkl-2020.2           | 138.3 MB  | ########2  |  83% \nmkl-2020.2           | 138.3 MB  | #########1 |  92% \nmkl-2020.2           | 138.3 MB  | ########## | 100% \n\nlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n\nsqlite-3.23.1        | 808 KB    |            |   0% \nsqlite-3.23.1        | 808 KB    | ########## | 100% \n\ncertifi-2021.5.30    | 139 KB    |            |   0% \ncertifi-2021.5.30    | 139 KB    | ########## | 100% \n\nzlib-1.2.12          | 103 KB    |            |   0% \nzlib-1.2.12          | 103 KB    | ########## | 100% \n\nthreadpoolctl-2.2.0  | 16 KB     |            |   0% \nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n\nmkl-service-2.3.0    | 52 KB     |            |   0% \nmkl-service-2.3.0    | 52 KB     | ########## | 100% \n\nnumpy-base-1.19.2    | 4.1 MB    |            |   0% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n\nintel-openmp-2022.1. | 4.5 MB    |            |   0% \nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \n\nncurses-6.0          | 781 KB    |            |   0% \nncurses-6.0          | 781 KB    | ########## | 100% \nncurses-6.0          | 781 KB    | ########## | 100% \n\nmkl_random-1.1.1     | 327 KB    |            |   0% \nmkl_random-1.1.1     | 327 KB    | ########## | 100% \n\nmkl_fft-1.3.0        | 170 KB    |            |   0% \nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \n\n_openmp_mutex-5.1    | 21 KB     |            |   0% \n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n\nca-certificates-2022 | 124 KB    |            |   0% \nca-certificates-2022 | 124 KB    | ########## | 100% \n\nxz-5.2.6             | 394 KB    |            |   0% \nxz-5.2.6             | 394 KB    | ########## | 100% \n\nopenssl-1.0.2u       | 2.2 MB    |            |   0% \nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \n\nwheel-0.37.1         | 33 KB     |            |   0% \nwheel-0.37.1         | 33 KB     | ########## | 100% \n\nlibedit-3.1          | 151 KB    |            |   0% \nlibedit-3.1          | 151 KB    | #          |  11% \nlibedit-3.1          | 151 KB    | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n\nlibffi-3.2.1         | 48 KB     |            |   0% \nlibffi-3.2.1         | 48 KB     | ########## | 100% \n\nscikit-learn-0.24.2  | 5.2 MB    |            |   0% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n\npython-3.6.2         | 23.6 MB   |            |   0% \npython-3.6.2         | 23.6 MB   |            |   0% \npython-3.6.2         | 23.6 MB   | 6          |   6% \npython-3.6.2         | 23.6 MB   | #8         |  18% \npython-3.6.2         | 23.6 MB   | ###4       |  35% \npython-3.6.2         | 23.6 MB   | #####8     |  58% \npython-3.6.2         | 23.6 MB   | ########## | 100% \npython-3.6.2         | 23.6 MB   | ########## | 100% \n\nlibgomp-11.2.0       | 474 KB    |            |   0% \nlibgomp-11.2.0       | 474 KB    | ########## | 100% \n\nnumpy-1.19.2         | 22 KB     |            |   0% \nnumpy-1.19.2         | 22 KB     | ########## | 100% \n\nlibgfortran4-7.5.0   | 995 KB    |            |   0% \nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n\nreadline-7.0         | 848 KB    |            |   0% \nreadline-7.0         | 848 KB    | ########## | 100% \n\nsix-1.16.0           | 18 KB     |            |   0% \nsix-1.16.0           | 18 KB     | ########## | 100% \n\npip-21.2.2           | 1.8 MB    |            |   0% \npip-21.2.2           | 1.8 MB    | ######3    |  63% \npip-21.2.2           | 1.8 MB    | ########## | 100% \n\nscipy-1.5.2          | 14.4 MB   |            |   0% \nscipy-1.5.2          | 14.4 MB   | ##7        |  28% \nscipy-1.5.2          | 14.4 MB   | ########## | 100% \nscipy-1.5.2          | 14.4 MB   | ########## | 100% \n\nblas-1.0             | 6 KB      |            |   0% \nblas-1.0             | 6 KB      | ########## | 100% \n\njoblib-1.0.1         | 208 KB    |            |   0% \njoblib-1.0.1         | 208 KB    | ########## | 100% \n\nsetuptools-58.0.4    | 788 KB    |            |   0% \nsetuptools-58.0.4    | 788 KB    | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \n\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n    More details are available here: https://intel.github.io/scikit-learn-intelex\n\n    For example:\n\n        $ conda install scikit-learn-intelex\n        $ python -m sklearnex my_application.py\n\n    \n\ndone\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.y96135x_.requirements.txt']\nPip subprocess output:\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.45.0-py3-none-any.whl (2.0 kB)\nCollecting azureml-core~=1.45.0\n  Downloading azureml_core-1.45.0.post2-py3-none-any.whl (3.1 MB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.45.0\n  Downloading azureml_dataset_runtime-1.45.0-py3-none-any.whl (2.3 kB)\nCollecting azureml-inference-server-http~=0.7.2\n  Downloading azureml_inference_server_http-0.7.6-py3-none-any.whl (56 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\nCollecting azure-mgmt-resource<22.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\nCollecting urllib3<2.0.0,>=1.23\n  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting python-dateutil<3.0.0,>=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.19.0-py2.py3-none-any.whl (83 kB)\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\nCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-10.0.0-py3-none-any.whl (489 kB)\nCollecting packaging<22.0,>=20.0\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting azure-core<2.0.0\n  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting azure-mgmt-containerregistry<11,>=8.2.0\n  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting docker<6.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting knack~=0.9.0\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting msrest<=0.7.1,>=0.5.1\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting pkginfo\n  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0\n  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting jmespath<2.0.0\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\nCollecting pytz\n  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting importlib-metadata<5,>=0.23\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\nCollecting typing-extensions>=4.0.1\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azure-core<2.0.0->azureml-core~=1.45.0->azureml-defaults->-r /azureml-environment-setup/condaenv.y96135x_.requirements.txt (line 1)) (1.16.0)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting azureml-dataprep<4.3.0a,>=4.2.0a\n  Downloading azureml_dataprep-4.2.2-py3-none-any.whl (43.4 MB)\nRequirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.45.0->azureml-defaults->-r /azureml-environment-setup/condaenv.y96135x_.requirements.txt (line 1)) (1.19.2)\nCollecting pyarrow<6.0.1,>=0.17.0\n  Downloading pyarrow-6.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.5 MB)\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting jsonschema\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nCollecting azureml-dataprep-rslex~=2.8.0dev0\n  Downloading azureml_dataprep_rslex-2.8.1-cp36-cp36m-manylinux2010_x86_64.whl (16.5 MB)\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting flask-cors~=3.0.1\n  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting flask<2.2.0\n  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\nCollecting inference-schema~=1.4.0\n  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv.y96135x_.requirements.txt (line 1)) (58.0.4)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\nCollecting Werkzeug>=2.0\n  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\nCollecting click>=7.1.2\n  Downloading click-8.0.4-py3-none-any.whl (97 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\nCollecting wrapt<=1.12.1,>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\nCollecting pygments\n  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\nCollecting tabulate\n  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.45.0->azureml-defaults->-r /azureml-environment-setup/condaenv.y96135x_.requirements.txt (line 1)) (2021.5.30)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.2-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\nCollecting opencensus<1.0.0,>=0.11.0\n  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\nCollecting opencensus-context>=0.1.3\n  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\nCollecting google-auth<3.0dev,>=1.25.0\n  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\nCollecting protobuf<5.0.0dev,>=3.15.0\n  Downloading protobuf-3.19.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting contextvars\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\nCollecting pyparsing!=3.0.5,>=2.0.2\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (594 kB)\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\nCollecting dataclasses\n  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting immutables>=0.9\n  Downloading immutables-0.19-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\nCollecting pyrsistent>=0.14.0\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=397ee88433d1f6c96aec04c259554b2b33477200dbf52b859995f8ad3a469d55\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=a41b305f29670683ddfab71363e8653728c84389e17578ab63c494ec1fab62d7\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76182 sha256=faebb8707779b3c399f077a7c9ba96fb0c772b2626f04ee9a89c817c199bb9a7\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for contextvars (setup.py): started\n  Building wheel for contextvars (setup.py): finished with status 'done'\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=27d0d3ed04dbe4cb1b882f723911683878c98ba5abb0334bcf2acf41bcad1164\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\nSuccessfully built json-logging-py fusepy wrapt contextvars\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, python-dateutil, pyrsistent, msal-extensions, MarkupSafe, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, dataclasses, contextvars, azure-core, attrs, Werkzeug, pyyaml, opencensus-context, msrest, jsonschema, Jinja2, itsdangerous, google-api-core, dotnetcore2, cloudpickle, click, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, websocket-client, tabulate, pytz, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, jeepney, flask, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask-cors, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.0.3 adal-1.2.7 argcomplete-2.0.0 attrs-22.1.0 azure-common-1.1.28 azure-core-1.24.2 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.0.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azureml-core-1.45.0.post2 azureml-dataprep-4.2.2 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.8.1 azureml-dataset-runtime-1.45.0 azureml-defaults-1.45.0 azureml-inference-server-http-0.7.6 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.0 cachetools-4.2.4 cffi-1.15.1 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.2.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-37.0.4 dataclasses-0.8 distro-1.7.0 docker-5.0.3 dotnetcore2-3.1.23 flask-2.0.3 flask-cors-3.0.10 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.12.0 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.9.0 msal-1.19.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.1 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.3 portalocker-2.5.1 protobuf-3.19.5 psutil-5.9.2 pyarrow-6.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.13.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.7 pyrsistent-0.18.0 python-dateutil-2.8.2 pytz-2022.2.1 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.12 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.11.0\n  latest version: 22.9.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0mWARNING: /root/.conda/pkgs does not exist\nRemoving intermediate container 1333d3dd3835\n ---> a13114092269\nStep 9/21 : ENV PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin:$PATH\n ---> Running in 7ae5d389620a\nRemoving intermediate container 7ae5d389620a\n ---> 7cc76f455967\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> d122768ae59f\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in 7584a6b8a019\nCopying environment context\nRemoving intermediate container 7584a6b8a019\n ---> 1ac13fc97993\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> 743a8a2fd00d\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 1b8a02ce7108\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container 1b8a02ce7108\n ---> eefb48416b8d\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 00226764a748\nRemoving intermediate container 00226764a748\n ---> f5c2041f4e9c\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib:$LD_LIBRARY_PATH\n ---> Running in 81df413892a5\nRemoving intermediate container 81df413892a5\n ---> fe68f15f6a05\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_e220b045f6c3c3008b1a386af067185d CONDA_PREFIX=/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in f2954933a215\nRemoving intermediate container f2954933a215\n ---> eb1f86034f4c\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> 086543b09991\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in f22276b8ee4d\nRemoving intermediate container f22276b8ee4d\n ---> f58d03f48b1a\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in 95e4482cfb83\nRemoving intermediate container 95e4482cfb83\n ---> acb4bed39e6e\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in 85f36f263491\nRemoving intermediate container 85f36f263491\n ---> 2f9984d88032\nStep 21/21 : CMD [\"bash\"]\n ---> Running in 40444b00ac52\nRemoving intermediate container 40444b00ac52\n ---> 68e3f58784a1\nSuccessfully built 68e3f58784a1\nSuccessfully tagged 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6:latest\nSuccessfully tagged 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6:1\n2022/09/29 09:42:56 Successfully executed container: acb_step_0\n2022/09/29 09:42:56 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/09/29 09:42:56 Pushing image: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6:1, attempt 1\nThe push refers to repository [7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6]\n28bf88ff684b: Preparing\n3b81fd3789bf: Preparing\n9acf1e1976de: Preparing\nd5b4ec7a1569: Preparing\nec36cfa6f6a6: Preparing\n5f32af6e3347: Preparing\n59f2e81a596f: Preparing\na67362aa1281: Preparing\n98b1672915a9: Preparing\n3b46ab6d7ccf: Preparing\ncc45347b4ace: Preparing\n1b372d66233e: Preparing\n07a28cde7d10: Preparing\n30396212e2bd: Preparing\ne2efb02e0592: Preparing\ndafbdffeff20: Preparing\n657ccef222ea: Preparing\na2fbf4296693: Preparing\n149bb2b607d0: Preparing\naf7ed92504ae: Preparing\n5f32af6e3347: Waiting\n59f2e81a596f: Waiting\na67362aa1281: Waiting\n98b1672915a9: Waiting\n3b46ab6d7ccf: Waiting\ncc45347b4ace: Waiting\n1b372d66233e: Waiting\n07a28cde7d10: Waiting\n30396212e2bd: Waiting\ne2efb02e0592: Waiting\ndafbdffeff20: Waiting\n657ccef222ea: Waiting\na2fbf4296693: Waiting\n149bb2b607d0: Waiting\naf7ed92504ae: Waiting\nd5b4ec7a1569: Pushed\n28bf88ff684b: Pushed\nec36cfa6f6a6: Pushed\n3b81fd3789bf: Pushed\n59f2e81a596f: Pushed\n9acf1e1976de: Pushed\n98b1672915a9: Pushed\na67362aa1281: Pushed\n3b46ab6d7ccf: Pushed\ncc45347b4ace: Pushed\n1b372d66233e: Pushed\n07a28cde7d10: Pushed\ndafbdffeff20: Pushed\n30396212e2bd: Pushed\n657ccef222ea: Pushed\na2fbf4296693: Pushed\ne2efb02e0592: Pushed\naf7ed92504ae: Pushed\n149bb2b607d0: Pushed\n5f32af6e3347: Pushed\n1: digest: sha256:7d303bc85c0dff55d870b95ff553a244bf1bcb8bb1bbc582d3c5fbce20fa55ba size: 4513\n2022/09/29 09:44:27 Successfully pushed image: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6:1\n2022/09/29 09:44:27 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/09/29 09:44:27 Pushing image: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6:latest, attempt 1\nThe push refers to repository [7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6]\n28bf88ff684b: Preparing\n3b81fd3789bf: Preparing\n9acf1e1976de: Preparing\nd5b4ec7a1569: Preparing\nec36cfa6f6a6: Preparing\n5f32af6e3347: Preparing\n59f2e81a596f: Preparing\na67362aa1281: Preparing\n98b1672915a9: Preparing\n3b46ab6d7ccf: Preparing\ncc45347b4ace: Preparing\n1b372d66233e: Preparing\n07a28cde7d10: Preparing\n30396212e2bd: Preparing\ne2efb02e0592: Preparing\ndafbdffeff20: Preparing\n657ccef222ea: Preparing\na2fbf4296693: Preparing\n149bb2b607d0: Preparing\naf7ed92504ae: Preparing\n5f32af6e3347: Waiting\n59f2e81a596f: Waiting\na67362aa1281: Waiting\n98b1672915a9: Waiting\n3b46ab6d7ccf: Waiting\ncc45347b4ace: Waiting\n1b372d66233e: Waiting\n07a28cde7d10: Waiting\n30396212e2bd: Waiting\ne2efb02e0592: Waiting\ndafbdffeff20: Waiting\n657ccef222ea: Waiting\na2fbf4296693: Waiting\n149bb2b607d0: Waiting\naf7ed92504ae: Waiting\nd5b4ec7a1569: Layer already exists\n9acf1e1976de: Layer already exists\n3b81fd3789bf: Layer already exists\n28bf88ff684b: Layer already exists\nec36cfa6f6a6: Layer already exists\na67362aa1281: Layer already exists\n5f32af6e3347: Layer already exists\n98b1672915a9: Layer already exists\n59f2e81a596f: Layer already exists\n1b372d66233e: Layer already exists\n30396212e2bd: Layer already exists\n3b46ab6d7ccf: Layer already exists\n07a28cde7d10: Layer already exists\ncc45347b4ace: Layer already exists\ndafbdffeff20: Layer already exists\n657ccef222ea: Layer already exists\ne2efb02e0592: Layer already exists\na2fbf4296693: Layer already exists\n149bb2b607d0: Layer already exists\naf7ed92504ae: Layer already exists\nlatest: digest: sha256:7d303bc85c0dff55d870b95ff553a244bf1bcb8bb1bbc582d3c5fbce20fa55ba size: 4513\n2022/09/29 09:44:28 Successfully pushed image: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io/azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6:latest\n2022/09/29 09:44:28 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 125.880385)\n2022/09/29 09:44:28 Populating digests for step ID: acb_step_0...\n2022/09/29 09:44:30 Successfully populated digests for step ID: acb_step_0\n2022/09/29 09:44:30 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 90.954185)\n2022/09/29 09:44:30 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.514329)\n2022/09/29 09:44:30 The following dependencies were found:\n2022/09/29 09:44:30 \n- image:\n    registry: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io\n    repository: azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6\n    tag: latest\n    digest: sha256:7d303bc85c0dff55d870b95ff553a244bf1bcb8bb1bbc582d3c5fbce20fa55ba\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20220708.v1\n    digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n  git: {}\n- image:\n    registry: 7184aac0cff54d64b0ec233fc6639f0e.azurecr.io\n    repository: azureml/azureml_3d9573a5eb84459cf62cf1152318fbf6\n    tag: \"1\"\n    digest: sha256:7d303bc85c0dff55d870b95ff553a244bf1bcb8bb1bbc582d3c5fbce20fa55ba\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20220708.v1\n    digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n  git: {}\n\n\nRun ID: dbm was successful after 3m43s\n\nStreaming azureml-logs/55_azureml-execution-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt\n========================================================================================================================\n2022-09-29T09:54:42Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=13194 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-09-29T09:54:42Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/mounts/workspaceblobstore -- stdout/stderr: \n2022-09-29T09:54:42Z The vmsize standard_d2as_v4 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-09-29T09:54:42Z Starting output-watcher...\n2022-09-29T09:54:43Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n70: Pulling from azureml/curated/sidecar\nd7bfe07ed847: Pulling fs layer\ndcef2ac699a5: Pulling fs layer\n42794fc92dfd: Pulling fs layer\n88af38890981: Pulling fs layer\n13e568c28e4b: Pulling fs layer\n18f510a7158e: Pulling fs layer\n8699f484c7da: Pulling fs layer\na7071d489c78: Pulling fs layer\nfd21b2f1d9b3: Pulling fs layer\nfe7fa5ee3450: Pulling fs layer\n2a563e3f81b0: Pulling fs layer\ndbc80e23976b: Pulling fs layer\n6b5e9388df31: Pulling fs layer\n758a21e0749e: Pulling fs layer\n8f938f45ed8d: Pulling fs layer\n4166290bcbdf: Pulling fs layer\n76cdfb5ed624: Pulling fs layer\n9148a687a452: Pulling fs layer\n4072ca38e5ac: Pulling fs layer\n2ded670cfa94: Pulling fs layer\n659846794281: Pulling fs layer\n194b3b1881f4: Pulling fs layer\n12f7815c54b8: Pulling fs layer\n88af38890981: Waiting\n13e568c28e4b: Waiting\n18f510a7158e: Waiting\n8699f484c7da: Waiting\na7071d489c78: Waiting\nfd21b2f1d9b3: Waiting\nfe7fa5ee3450: Waiting\n2a563e3f81b0: Waiting\ndbc80e23976b: Waiting\n6b5e9388df31: Waiting\n758a21e0749e: Waiting\n8f938f45ed8d: Waiting\n4166290bcbdf: Waiting\n76cdfb5ed624: Waiting\n9148a687a452: Waiting\n4072ca38e5ac: Waiting\n2ded670cfa94: Waiting\n659846794281: Waiting\n12f7815c54b8: Waiting\n194b3b1881f4: Waiting\nd7bfe07ed847: Verifying Checksum\nd7bfe07ed847: Download complete\n42794fc92dfd: Verifying Checksum\n42794fc92dfd: Download complete\n13e568c28e4b: Verifying Checksum\n13e568c28e4b: Download complete\n88af38890981: Verifying Checksum\n88af38890981: Download complete\n8699f484c7da: Verifying Checksum\n8699f484c7da: Download complete\na7071d489c78: Verifying Checksum\na7071d489c78: Download complete\n18f510a7158e: Verifying Checksum\n18f510a7158e: Download complete\nfe7fa5ee3450: Verifying Checksum\nfe7fa5ee3450: Download complete\nfd21b2f1d9b3: Verifying Checksum\nfd21b2f1d9b3: Download complete\ndbc80e23976b: Verifying Checksum\ndbc80e23976b: Download complete\nd7bfe07ed847: Pull complete\n2a563e3f81b0: Verifying Checksum\n2a563e3f81b0: Download complete\ndcef2ac699a5: Verifying Checksum\ndcef2ac699a5: Download complete\n8f938f45ed8d: Verifying Checksum\n8f938f45ed8d: Download complete\n4166290bcbdf: Verifying Checksum\n4166290bcbdf: Download complete\n76cdfb5ed624: Verifying Checksum\n76cdfb5ed624: Download complete\n9148a687a452: Verifying Checksum\n9148a687a452: Download complete\n4072ca38e5ac: Verifying Checksum\n4072ca38e5ac: Download complete\n2ded670cfa94: Verifying Checksum\n2ded670cfa94: Download complete\n659846794281: Verifying Checksum\n659846794281: Download complete\n194b3b1881f4: Verifying Checksum\n194b3b1881f4: Download complete\n12f7815c54b8: Verifying Checksum\n12f7815c54b8: Download complete\n758a21e0749e: Verifying Checksum\n758a21e0749e: Download complete\n6b5e9388df31: Verifying Checksum\n6b5e9388df31: Download complete\ndcef2ac699a5: Pull complete\n42794fc92dfd: Pull complete\n88af38890981: Pull complete\n13e568c28e4b: Pull complete\n18f510a7158e: Pull complete\n8699f484c7da: Pull complete\na7071d489c78: Pull complete\nfd21b2f1d9b3: Pull complete\nfe7fa5ee3450: Pull complete\n2a563e3f81b0: Pull complete\ndbc80e23976b: Pull complete\n6b5e9388df31: Pull complete\n758a21e0749e: Pull complete\n8f938f45ed8d: Pull complete\n4166290bcbdf: Pull complete\n76cdfb5ed624: Pull complete\n9148a687a452: Pull complete\n4072ca38e5ac: Pull complete\n2ded670cfa94: Pull complete\n659846794281: Pull complete\n194b3b1881f4: Pull complete\n12f7815c54b8: Pull complete\nDigest: sha256:c5931fb3fb96642b435e66bd759c6595577396ede63973b46a987e6398dd8690\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/curated/sidecar:70\nmcr.microsoft.com/azureml/curated/sidecar:70\n2022-09-29T09:55:16Z The vmsize standard_d2as_v4 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-09-29T09:55:16Z Check if container 4742184a-632f-4e2e-9332-700dbcb91e5a_DataSidecar already exist exited with 0, \n\n637040fbf83da0ae0ff5ea345fdb7931ae99f7a6cc7822afce7af9a4408a3af8\n2022-09-29T09:55:17Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-09-29T09:55:17Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-60a21d0075fe5a72663e3f94ca4d16bb-86ca3e72ce585f68-01 -sshRequired=false] \n2022/09/29 09:55:18 Didn't get JobInfoJson from env, now read from file\n2022/09/29 09:55:18 Suceeded read JobInfoJson from file\n2022/09/29 09:55:18 Starting App Insight Logger for task:  containerSetup\n2022/09/29 09:55:18 Version: 3.0.02076.0001 Branch: .SourceBranch Commit: 3000b3f\n2022/09/29 09:55:18 Entered ContainerSetupTask - Preparing infiniband\n2022/09/29 09:55:18 Starting infiniband setup\n2022/09/29 09:55:18 Python Version found is Python 3.8.12\n\n2022/09/29 09:55:18 Returning Python Version as 3.8\n2022/09/29 09:55:18 VMSize: standard_d2as_v4, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/09/29 09:55:18 VMSize: standard_d2as_v4, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022-09-29T09:55:18Z VMSize: standard_d2as_v4, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/09/29 09:55:18 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022/09/29 09:55:18 Not setting up Infiniband in Container\n2022/09/29 09:55:18 Not setting up Infiniband in Container\n2022-09-29T09:55:18Z Not setting up Infiniband in Container\n2022/09/29 09:55:18 Python Version found is Python 3.8.12\n\n2022/09/29 09:55:18 Returning Python Version as 3.8\n2022/09/29 09:55:18 sshd inside container not required for job, skipping setup.\n2022/09/29 09:55:18 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/09/29 09:55:18 App Insight Client has already been closed\n2022/09/29 09:55:18 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-09-29T09:55:18Z Starting docker container succeeded.\n2022-09-29T09:55:18Z The vmsize standard_d2as_v4 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n\nStreaming azureml-logs/65_job_prep-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt\n===============================================================================================================\n[2022-09-29T09:55:35.250381] Entering job preparation.\n[2022-09-29T09:55:36.087750] Starting job preparation.\n[2022-09-29T09:55:36.087785] Extracting the control code.\n[2022-09-29T09:55:36.088085] Starting extract_project.\n[2022-09-29T09:55:36.088124] Starting to extract zip file.\n[2022-09-29T09:55:36.216220] Finished extracting zip file.\n[2022-09-29T09:55:36.219886] Using urllib.request Python 3.0 or later\n[2022-09-29T09:55:36.219935] Start fetching snapshots.\n[2022-09-29T09:55:36.219971] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 45\n[2022-09-29T09:55:36.415350] Finished fetching snapshot.\n[2022-09-29T09:55:36.415721] Start fetching snapshot.\n\nStreaming azureml-logs/65_job_prep-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt\n===============================================================================================================\n[2022-09-29T09:55:20.101871] Entering job preparation.\n[2022-09-29T09:55:20.699306] Starting job preparation.\n[2022-09-29T09:55:20.699333] Extracting the control code.\n[2022-09-29T09:55:20.699619] Starting extract_project.\n[2022-09-29T09:55:20.699655] Starting to extract zip file.\n[2022-09-29T09:55:20.808075] Finished extracting zip file.\n[2022-09-29T09:55:20.811236] Using urllib.request Python 3.0 or later\n[2022-09-29T09:55:20.811267] Start fetching snapshots.\n[2022-09-29T09:55:20.811297] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 50\n[2022-09-29T09:55:21.305307] Finished fetching snapshot.\n[2022-09-29T09:55:21.305348] Start fetching snapshot.\n[2022-09-29T09:55:28.293866] Finished fetching snapshot.\n[2022-09-29T09:55:28.293928] Finished fetching snapshots.\n[2022-09-29T09:55:28.293939] Finished extract_project.\n[2022-09-29T09:55:28.294108] Finished fetching and extracting the control code.\n[2022-09-29T09:55:28.301559] Start run_history_prep.\n[2022-09-29T09:55:28.307137] Job preparation is complete.\n[2022-09-29T09:55:28.307254] Entering Data Context Managers in Sidecar\n[2022-09-29T09:55:28.308098] Running Sidecar prep cmd...\n[2022-09-29T09:55:28.770821] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a\n[2022-09-29T09:55:28.771679] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2022-09-29T09:55:28.998] Enter __enter__ of DatasetContextManager\n[2022-09-29T09:55:28.999] SDK version: azureml-core==0.1.0.66253449 azureml-dataprep==4.1.0. Session id: 545028f7-a33d-4ebc-859d-9fd1bd98eda5. Run id: 4742184a-632f-4e2e-9332-700dbcb91e5a.\n[2022-09-29T09:55:28.999] Processing 'batchdatayk'.\n[2022-09-29T09:55:28.999] Mode: 'mount'.\n[2022-09-29T09:55:28.999] Path on compute is specified: 'False'.\n[2022-09-29T09:55:29.000] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: batchdatayk\n[2022-09-29T09:55:30.433] Processing dataset FileDataset\n{\n  \"source\": [\n    \"('workspaceblobstore', 'batch-data-yk/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"c19b7492-db27-430a-9a04-1a990fa47e28\",\n    \"name\": \"batchdatayk\",\n    \"version\": 2,\n    \"description\": \"batch data\",\n    \"workspace\": \"Workspace.create(name='ml-workspace', subscription_id='1a15a546-9f17-4a32-a1b6-da7850ab3d04', resource_group='machinelearningexperiments')\"\n  }\n}\n[2022-09-29T09:55:31.103] Mounting batchdatayk to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28 as folder.\n[2022-09-29T09:55:31.103] Processing 'inferences'.\n[2022-09-29T09:55:31.103] Mode: 'mount'.\n[2022-09-29T09:55:31.103] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore'.\n[2022-09-29T09:55:31.180] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore\n[2022-09-29T09:55:31.180] Output is not a single file\n[2022-09-29T09:55:31.181] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore as folder\n[2022-09-29T09:55:31.993] Mounting INPUT_batchdatayk to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28.\n[2022-09-29T09:55:33.000] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore.\n[2022-09-29T09:55:33.001] Mounted INPUT_batchdatayk to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28.\n[2022-09-29T09:55:38.062] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore.\n[2022-09-29T09:55:38.068] Exit __enter__ of DatasetContextManager\nuri entered in sidecar: None\nSet Dataset batchdatayk's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28\nSet OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore\n[2022-09-29T09:55:38.069042] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2022-09-29T09:55:38.084160] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'BATCHDATAYK' with value '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28'.\n[2022-09-29T09:55:38.084552] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'inferences' with value '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore'.\n[2022-09-29T09:55:38.084789] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'batchdatayk' with value '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28'.\n[2022-09-29T09:55:38.085033] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZUREML_DATAREFERENCE_batchdatayk' with value '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28'.\n[2022-09-29T09:55:38.085483] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZURE_ML_INPUT_batchdatayk' with value '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28'.\n[2022-09-29T09:55:38.090498] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZURE_ML_OUTPUT_inferences' with value '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore'.\n[2022-09-29T09:55:38.090794] INFO azureml.sidecar.task.enter_contexts: New or updated environment variable 'AZUREML_SIDECAR_PATHS_TO_BIND' with value '[\"/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28:/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/a'.\n[2022-09-29T09:55:38.184926] Ran Sidecar prep cmd.\n[2022-09-29T09:55:38.185007] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2022/09/29 09:56:28 Didn't get JobInfoJson from env, now read from file\n2022/09/29 09:56:28 Suceeded read JobInfoJson from file\n2022/09/29 09:56:28 Starting App Insight Logger for task:  runTaskLet\n2022/09/29 09:56:28 Version: 3.0.02076.0001 Branch: .SourceBranch Commit: 3000b3f\n2022/09/29 09:56:28 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n2022/09/29 09:56:28 Send process info logs to master server succeeded\n2022/09/29 09:56:28 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n2022/09/29 09:56:28 Send process info logs to master server succeeded\n[2022-09-29T09:56:28.959869] Entering context manager injector.\n/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n  from cryptography.hazmat.backends import default_backend\n[2022-09-29T09:56:29.458524] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.44.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'batchdatayk'])\nScript type = None\n[2022-09-29T09:56:29.461692] Entering Run History Context Manager.\n[2022-09-29T09:56:30.071460] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a\n[2022-09-29T09:56:30.071653] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.44.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZURE_ML_OUTPUT_inferences', '--input_fds_0', 'batchdatayk']\n[2022-09-29T09:56:30.071723] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.44.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore', '--input_fds_0', 'batchdatayk']\n\n2022/09/29 09:56:33 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n\nStreaming azureml-logs/75_job_post-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt\n===============================================================================================================\n[2022-09-29T09:57:18.331661] Entering job release\n[2022-09-29T09:57:19.077910] Starting job release\n[2022-09-29T09:57:19.078372] Logging experiment finalizing status in history service.[2022-09-29T09:57:19.078564] job release stage : upload_datastore starting...\n\nStarting the daemon thread to refresh tokens in background for process with pid = 320[2022-09-29T09:57:19.081726] job release stage : start importing azureml.history._tracking in run_history_release.[2022-09-29T09:57:19.082003] Entering context manager injector.\n\n\n[2022-09-29T09:57:19.082288] job release stage : execute_job_release starting...\n[2022-09-29T09:57:19.082974] job release stage : copy_batchai_cached_logs starting...\n[2022-09-29T09:57:19.085108] job release stage : copy_batchai_cached_logs completed...\n[2022-09-29T09:57:19.097297] job release stage : upload_datastore completed...\n[2022-09-29T09:57:19.159966] job release stage : send_run_telemetry starting...\n[2022-09-29T09:57:19.185922] get vm size and vm region successfully.\n[2022-09-29T09:57:19.214106] get compute meta data successfully.\n[2022-09-29T09:57:19.267101] job release stage : execute_job_release completed...\n[2022-09-29T09:57:19.356393] post artifact meta request successfully.\n[2022-09-29T09:57:19.397941] upload compute record artifact successfully.\n[2022-09-29T09:57:19.398033] job release stage : send_run_telemetry completed...\n[2022-09-29T09:57:19.398533] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-09-29T09:57:19.398730] Running Sidecar release cmd...\n[2022-09-29T09:57:19.407733] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a\n[2022-09-29T09:57:19.417] Enter __exit__ of DatasetContextManager\n[2022-09-29T09:57:19.417] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28.\n[2022-09-29T09:57:20.426] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28.\n[2022-09-29T09:57:20.426] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore.\n[2022-09-29T09:57:20.443] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore.\n[2022-09-29T09:57:20.443] Exit __exit__ of DatasetContextManager\n[2022-09-29T09:57:20.443448] Removing absolute paths from host...\n[2022-09-29T09:57:20.443650] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-09-29T09:57:20.564176] Ran Sidecar release cmd.\n[2022-09-29T09:57:20.564277] Job release is complete\n\nStreaming azureml-logs/75_job_post-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt\n===============================================================================================================\n[2022-09-29T09:57:19.206662] Entering job release\n[2022-09-29T09:57:20.340673] job release stage : copy_batchai_cached_logs starting...\n[2022-09-29T09:57:20.340706] job release stage : copy_batchai_cached_logs completed...\n[2022-09-29T09:57:20.340743] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-09-29T09:57:20.341366] Running Sidecar release cmd...\n[2022-09-29T09:57:20.348762] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a\n[2022-09-29T09:57:20.359] Enter __exit__ of DatasetContextManager\n[2022-09-29T09:57:20.359] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28.\n[2022-09-29T09:57:21.362] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/batchdatayk_c19b7492-db27-430a-9a04-1a990fa47e28.\n[2022-09-29T09:57:21.362] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore.\n[2022-09-29T09:57:21.384] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace/azureml/4742184a-632f-4e2e-9332-700dbcb91e5a/wd/inferences_workspaceblobstore.\n[2022-09-29T09:57:21.384] Exit __exit__ of DatasetContextManager\n[2022-09-29T09:57:21.384812] Removing absolute paths from host...\n[2022-09-29T09:57:21.384993] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-09-29T09:57:21.472990] Ran Sidecar release cmd.\n\nStepRun(batch-score-diabetes) Execution Summary\n================================================\nStepRun( batch-score-diabetes ) Status: Finished\n{'runId': '4742184a-632f-4e2e-9332-700dbcb91e5a', 'target': 'yk-compute-cluster', 'status': 'Completed', 'startTimeUtc': '2022-09-29T09:54:39.283949Z', 'endTimeUtc': '2022-09-29T09:57:30.934218Z', 'services': {}, 'properties': {'ContentSnapshotId': 'c6208ace-a156-4ea3-9085-4975c389c043', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '65c039e3-182a-48ee-ba32-6a21f0885367', 'azureml.moduleName': 'batch-score-diabetes', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '204064bc', 'azureml.pipelinerunid': '6ddc4b06-fdef-426d-a46b-bebaf785d187', 'azureml.pipeline': '6ddc4b06-fdef-426d-a46b-bebaf785d187', 'azureml.pipelineComponent': 'masterescloud', 'azureml.parallelrunstep': 'true', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'c19b7492-db27-430a-9a04-1a990fa47e28'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'batchdatayk', 'mechanism': 'Mount'}}], 'outputDatasets': [{'identifier': {'savedId': '8bee2923-ac60-47bd-a26a-c50e7a986c98'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/4742184a-632f-4e2e-9332-700dbcb91e5a/inferences/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"8bee2923-ac60-47bd-a26a-c50e7a986c98\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='ml-workspace', subscription_id='1a15a546-9f17-4a32-a1b6-da7850ab3d04', resource_group='machinelearningexperiments')\"\n  }\n}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.44.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'batchdatayk'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'yk-compute-cluster', 'dataReferences': {}, 'data': {'batchdatayk': {'dataLocation': {'dataset': {'id': 'c19b7492-db27-430a-9a04-1a990fa47e28', 'name': None, 'version': '2'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'batchdatayk', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '6ddc4b06-fdef-426d-a46b-bebaf785d187', 'azureml.pipelineRun.moduleNodeId': '204064bc', 'azureml.pipelineRun.outputPortName': 'inferences'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2022-09-29T09:40:44Z_47923b9c', 'assetId': 'azureml://locations/uksouth/workspaces/7184aac0-cff5-4d64-b0ec-233fc6639f0e/environments/experiment_env/versions/Autosave_2022-09-29T09:40:44Z_47923b9c', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'batch_environment', 'dependencies': ['python=3.6.2', 'scikit-learn', 'pip', {'pip': ['azureml-defaults']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=g8H6H7WzHhAbL0HpGfzSLUbgJbP9rOj5HJ%2BjPFOddy0%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/55_azureml-execution-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt?sv=2019-07-07&sr=b&sig=w7Gqti9dFXX6ZOs7OMis7mzZ38XjPUcfB204YRqSldc%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/55_azureml-execution-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt?sv=2019-07-07&sr=b&sig=TbCiVPm6xJTklI2lKAf4BCeV22sUe5f3Sve7hkglJoo%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/65_job_prep-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/65_job_prep-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt?sv=2019-07-07&sr=b&sig=7q%2FAgMkkei6R0xkhUm1PMF5TgpVlTBTPkguPl3s1N28%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/65_job_prep-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt?sv=2019-07-07&sr=b&sig=kdYEvJQpQyYcuMzQ%2FMtfxoHHouvt83%2FqWLFmtc7BaYs%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=%2B9LB4utL1a1Kc5GBfYyQ50eVjdIHRAX754VAlhpkG1k%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/75_job_post-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/75_job_post-tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d.txt?sv=2019-07-07&sr=b&sig=30q9J3hYC02UvS9cXOSE3mJUdAfaPnVfu9%2Fb%2BRo39Sk%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/75_job_post-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/75_job_post-tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d.txt?sv=2019-07-07&sr=b&sig=UO%2FPMLgxf9IA3tP9V4KUJxJHwJab7MttRoUcOKRxipg%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/process_info.json': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=tKm5auI8eU4MLkCJp%2BnuWDdzSAlBT0pxYkB4qRqOUDY%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'azureml-logs/process_status.json': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=9JipC3UfDzVLQFUInft%2BNJML8Vx9CO2ypKO4OiOymZQ%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/116_azureml.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/116_azureml.log?sv=2019-07-07&sr=b&sig=%2FSruZyj4oqv2be2HPklU50CFhkceBImjJmImVlakqWM%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/89_azureml.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/89_azureml.log?sv=2019-07-07&sr=b&sig=E2dgj7yryia66iLCqcP%2F6r5m5Qn2L9PnMssNictosSk%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=hiNmh4jZL2im7icbLmqRfmAi%2FcOUDRM8wr8PhcwtoWQ%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=TmR6YIOMqP0j3Grg%2BD8SxwGg9LVdQ9M1z4bbPazCsGw%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=LS8X%2B6D7nYx2g6eoZ1Smfoj0dbAKy6SxCJsPiXFMu84%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d/all.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/sidecar/tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d/all.log?sv=2019-07-07&sr=b&sig=zo986IZzZ1Da12zC4EmrYw4PO%2Bp8GMZTjU7Q%2BvjNnzA%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d/task.enter_contexts.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/sidecar/tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=c75rInk2dxVSxuY7GVY3jB1hq1AMIEfoRJAydiCUldM%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d/task.exit_contexts.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/sidecar/tvmps_73647da0a9ec9b59e975de2db90a56de89116f97acb9b524de0052a360ef0666_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=sv%2B9xk7Ot52fGBcO7r1rirAZM%2BVaHxyYhqm%2Bf7NZZac%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d/all.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/sidecar/tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d/all.log?sv=2019-07-07&sr=b&sig=mZ4Tf1vh3DaewL%2FuvttEM2m94pbDI1xzxrwCDDfSWNU%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d/task.enter_contexts.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/sidecar/tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=lua0uniLDGcYwR8apP1pvVjHgbN2aTvfCRIth5sMAr8%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/sidecar/tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d/task.exit_contexts.log': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/sidecar/tvmps_b91e5801855f3816584aeedcbc5022e4a1bdf48f5d351d9bc63ffc78ea757137_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=LUv4oPEtdRzi120bYapJtruAoBQXBLBWGtYRS1AIiI8%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=HOp4%2BtSvcz7PX7IyjpetOmo2RsPasUZ19mvta5bCJj4%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.4742184a-632f-4e2e-9332-700dbcb91e5a/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=xLNENHDjRKzpjndWeA3f87BfQ3SuWMOWIP8iMYp%2Bz1o%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A24Z&se=2022-09-29T17%3A57%3A24Z&sp=r'}, 'submittedBy': 'Yeliz Kilinc'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '6ddc4b06-fdef-426d-a46b-bebaf785d187', 'status': 'Completed', 'startTimeUtc': '2022-09-29T09:39:52.227107Z', 'endTimeUtc': '2022-09-29T09:57:32.382524Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.6ddc4b06-fdef-426d-a46b-bebaf785d187/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=d7E7kMmu%2FF2laFQbkXlB7eYBwoBp90OvukUrf6G7dTw%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A34Z&se=2022-09-29T17%3A57%3A34Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.6ddc4b06-fdef-426d-a46b-bebaf785d187/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=uQYBaGJlIaHjzn7uR8xnja9wBcpqu2wwabZnE5Ubvno%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A34Z&se=2022-09-29T17%3A57%3A34Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlworkspace0379851735.blob.core.windows.net/azureml/ExperimentRun/dcid.6ddc4b06-fdef-426d-a46b-bebaf785d187/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=eGnOWG7zftfDGXWwomt28Xs%2FX4fbYPNEJyu1Y%2FRtI50%3D&skoid=9aa8775e-dbe0-44f3-9953-3474fd3d2e59&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-29T08%3A28%3A57Z&ske=2022-09-30T16%3A38%3A57Z&sks=b&skv=2019-07-07&st=2022-09-29T09%3A47%3A34Z&se=2022-09-29T17%3A57%3A34Z&sp=r'}, 'submittedBy': 'Yeliz Kilinc'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-batch-pipeline,\nId: 9c2b7357-2dd0-45b6-a2e3-c9a8e672ed97,\nStatus: Active,\nEndpoint: https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourceGroups/machinelearningexperiments/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/PipelineRuns/PipelineSubmit/9c2b7357-2dd0-45b6-a2e3-c9a8e672ed97)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/9c2b7357-2dd0-45b6-a2e3-c9a8e672ed97?wsid=/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourcegroups/machinelearningexperiments/workspaces/ml-workspace\" target=\"_blank\" rel=\"noopener\">9c2b7357-2dd0-45b6-a2e3-c9a8e672ed97</a></td><td>Active</td><td><a href=\"https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourceGroups/machinelearningexperiments/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/PipelineRuns/PipelineSubmit/9c2b7357-2dd0-45b6-a2e3-c9a8e672ed97\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/1a15a546-9f17-4a32-a1b6-da7850ab3d04/resourceGroups/machinelearningexperiments/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/PipelineRuns/PipelineSubmit/9c2b7357-2dd0-45b6-a2e3-c9a8e672ed97\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Schedule,ScheduleRecurrence\r\n",
        "\r\n",
        "weekly=ScheduleRecurrence(frequency='Week',interval=1)\r\n",
        "pipeline_schedule=Schedule.create(ws,\r\n",
        "name='weekly predictions',\r\n",
        "pipeline_id=published_pipeline.id,\r\n",
        "experiment_name='Batch_predictions',\r\n",
        "recurrence=weekly)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deploy_batch_scoring_pipeline.py\r\n",
        "ws = Workspace.from_config()\r\n",
        "env = Environment.get(workspace=ws, name=config['batch_env_name'])\r\n",
        "runconfig = RunConfiguration()\r\n",
        "runconfig.environment = env\r\n",
        "\r\n",
        "# Dataset input and output\r\n",
        "batch_dataset = Dataset.get_by_name(ws, config['batch_input_dataset_name'])\r\n",
        "batch_dataset_parameter = PipelineParameter(name=\"batch_dataset\", default_value=batch_dataset)\r\n",
        "batch_dataset_consumption = DatasetConsumptionConfig(\"batch_dataset\", batch_dataset_parameter).as_download()\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "output_dataset = OutputFileDatasetConfig(name='batch_results',\r\n",
        "                                         destination=(datastore, config['batch_output_path_on_datastore'])).register_on_complete(name=config['batch_output_dataset_name'])\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory=\"data-science/src/\",\r\n",
        "    entry_script=\"score.py\",\r\n",
        "    environment=env,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    append_row_file_name=config['batch_output_filename'],\r\n",
        "    mini_batch_size=config['batch_mini_batch_size'],\r\n",
        "    error_threshold=config['batch_error_threshold'],\r\n",
        "    compute_target=config['batch_target'],\r\n",
        "    process_count_per_node=config['batch_process_count_per_node'],\r\n",
        "    node_count=config['batch_node_count']\r\n",
        ")\r\n",
        "\r\n",
        "batch_step = ParallelRunStep(\r\n",
        "    name=\"batch-step\",\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    arguments=['--model_name', config['model_name'], '--enable_monitoring', args.m, '--table_name', config[\"scoring_table_name\"]],\r\n",
        "    inputs=[batch_dataset_consumption],\r\n",
        "    side_inputs=[],\r\n",
        "    output=output_dataset,\r\n",
        "    allow_reuse=False\r\n",
        ")\r\n",
        "\r\n",
        "steps = [batch_step]\r\n",
        "\r\n",
        "print('Creating, validating, and publishing pipeline')\r\n",
        "#print('Creating, validating, and publishing pipeline')\r\n",
        "#pipeline = Pipeline(workspace=ws, steps=steps)\r\n",
        "#pipeline.validate()\r\n",
        "#published_pipeline = pipeline.publish(config['training_pipeline_name'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add pipeline to an endpoint\r\n",
        "import argparse\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "from azureml.pipeline.core import PublishedPipeline, PipelineEndpoint\r\n",
        "\r\n",
        "print(\"Azure ML SDK version:\", azureml.core.VERSION)\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser(\"Add pipeline to pipeline endpoint\")\r\n",
        "parser.add_argument(\"-p\", type=str, help=\"Pipeline ID of pipeline to add\")\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "pipeline_id = args.p\r\n",
        "published_pipeline = PublishedPipeline.get(workspace=ws, id=pipeline_id)\r\n",
        "endpoint_name = published_pipeline.name + '-endpoint'\r\n",
        "\r\n",
        "try:\r\n",
        "    pl_endpoint = PipelineEndpoint.get(workspace=ws, name=endpoint_name)\r\n",
        "    pl_endpoint.add_default(published_pipeline)\r\n",
        "    print(f'Added pipeline {pipeline_id} to Pipeline Endpoint with name {endpoint_name}')\r\n",
        "except Exception:\r\n",
        "    print(f'Will create new Pipeline Endpoint with name {endpoint_name} with pipeline {pipeline_id}')\r\n",
        "    pl_endpoint = PipelineEndpoint.publish(workspace=ws,\r\n",
        "                                           name=endpoint_name,\r\n",
        "                                           pipeline=published_pipeline,\r\n",
        "                                           description='Published by MLOps V2')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#run_pipeline.py\r\n",
        "import argparse\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Experiment\r\n",
        "from azureml.pipeline.core import PublishedPipeline\r\n",
        "\r\n",
        "print(\"Azure ML SDK version:\", azureml.core.VERSION)\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser(\"Run Pipeline\")\r\n",
        "parser.add_argument(\"-p\", type=str, help=\"Pipeline Id\")\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "pipeline = PublishedPipeline.get(workspace=ws, id=args.p)\r\n",
        "experiment_name = pipeline.name + '-ci'\r\n",
        "pipeline_run = Experiment(ws, experiment_name).submit(pipeline, regenerate_outputs=True)\r\n",
        "print(pipeline_run)\r\n",
        "pipeline_run.wait_for_completion()"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Once the inference pipeline is created, we can deploy the model to an endpoint"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}