{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.train.automl import AutoMLConfig"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665985882740
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#authentication\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ia = InteractiveLoginAuthentication(tenant_id='16b3c013-d300-468d-ac64-7eda0820b6d3')\r\n",
        "\r\n",
        "# You can find tenant id under azure active directory->properties\r\n",
        "ws = Workspace.get(name='Prod',\r\n",
        "                     subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873',\r\n",
        "                     resource_group='ProdRG',auth=ia)"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987287926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute target - you can use different compute targets in different steps in the pipeline\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "pipeline_cluster = \"Demo-Compute-Cluster\"\r\n",
        "compute_target = ws.compute_targets[pipeline_cluster]"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665985891862
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "data = pd.read_csv(\r\n",
        "    \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\r\n",
        ")\r\n",
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "   age          job  marital    education  default housing loan    contact  \\\n0   57   technician  married  high.school       no      no  yes   cellular   \n1   55      unknown  married      unknown  unknown     yes   no  telephone   \n2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n3   36       admin.  married  high.school       no      no   no  telephone   \n4   27    housemaid  married  high.school       no     yes   no   cellular   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         1      failure         -1.8   \n1   may         thu  ...         2    999         0  nonexistent          1.1   \n2   may         fri  ...         1    999         1      failure         -1.8   \n3   jun         fri  ...         4    999         0  nonexistent          1.4   \n4   jul         fri  ...         2    999         0  nonexistent          1.4   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          92.893          -46.2      1.299       5099.1  no  \n1          93.994          -36.4      4.860       5191.0  no  \n2          92.893          -46.2      1.313       5099.1  no  \n3          94.465          -41.8      4.967       5228.1  no  \n4          93.918          -42.7      4.963       5228.1  no  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.299</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>unknown</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>thu</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.860</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.9y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.313</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>4</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.967</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.918</td>\n      <td>-42.7</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665986431965
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we will store intermediate data between data preparation step and autoML step in the default datastore of the workspace.\r\n",
        "datastore = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987304612
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "dataset = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    data, target=(datastore, \"dataset\"), name=\"AutoMLE2ETraininggPipeline_Classification_dataset\"\r\n",
        ")\r\n",
        "#I creat dataset from pandas dataframe.\r\n",
        "#Other way: You can create  tabular dataset by using ds=Dataset.Tabular.from_delimited_files(path=xxx) and register it with ds.register()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to dataset/3b7eaf49-af2d-493b-88a7-22e9586cc15f/\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987308010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Target: Configure the training run- Environment setup\r\n",
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#env = Environment.get(workspace=ws, name='experiment_env', version='2')\r\n",
        "curated_env=Environment.get(workspace=ws, name='AzureML-sklearn-1.0-ubuntu20.04-py38-cpu')\r\n",
        "pipeline_run_config=RunConfiguration()\r\n",
        "pipeline_run_config.environment=curated_env\r\n",
        "\r\n",
        "# Add conda dependencies to the automl env:\r\n",
        "#pipeline_run_config.environment.python.conda_dependencies = CondaDependencies.create(\r\n",
        " #conda_packages=['pandas'])  "
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987317859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "#1st way: OutputFileDatasetConfig without giving destination\r\n",
        "#prepped_output_path = OutputFileDatasetConfig(name=\"output_path\") \r\n",
        "# OutputFileDatasetConfig  points a directory and CSV file will be written there. Also given as parameter below.\r\n",
        "# If you do not give destination parameter, it will copy the output to the workspaceblobstore datastore, under the path /dataset/{run-id}/{output-name}. \r\n",
        "# Run-id is the name value on the overview of the job and outputname is the name given as a parameter. In my example, it is output_path.\r\n",
        "\r\n",
        "#2nd way: OutputFileDatasetConfig with giving destination\r\n",
        "output_path = (datastore, f\"azureml/classification_prep_output/\")\r\n",
        "prepped_output_path = OutputFileDatasetConfig(destination = output_path)\r\n",
        "\r\n",
        "input_ds = Dataset.get_by_name(ws, 'AutoMLE2ETraininggPipeline_Classification_dataset')\r\n",
        "\r\n",
        "prep_step=PythonScriptStep(\r\n",
        "    name=\"Prepare AutoML Classification\",\r\n",
        "    script_name=\"prepare.py\",\r\n",
        "    source_directory=\"./Scripts\",\r\n",
        "    #arguments=['--input-data',input_ds.as_named_input('AutoMLE2ETraininggPipeline_Classification_dataset'),'--prepped-data',output],\r\n",
        "    arguments=[\"--output_path\",prepped_output_path],\r\n",
        "    inputs=[input_ds.as_named_input('AutoMLE2ETraininggPipeline_Classification_dataset')],\r\n",
        "    compute_target=compute_target,\r\n",
        "    runconfig=pipeline_run_config\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987318021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In an ML pipeline, the input data must be a Dataset object.\r\n",
        "\r\n",
        "prepped_test_data=prepped_output_path.read_delimited_files(\"prepped_train_data_classification.csv\") # This is the test data to send automlstep\r\n",
        "prepped_train_data = prepped_output_path.read_delimited_files(\"prepped_test_data_classification.csv\")\r\n",
        "\r\n",
        "from azureml.pipeline.core import TrainingOutput,PipelineData\r\n",
        "\r\n",
        "metrics_data = PipelineData(name='metrics_data',\r\n",
        "                            datastore=datastore,\r\n",
        "                            pipeline_output_name='metrics_output',\r\n",
        "                            training_output=TrainingOutput(type='Metrics'))\r\n",
        "\r\n",
        "model_data = PipelineData(name='best_model_data',\r\n",
        "                          datastore=datastore,\r\n",
        "                          pipeline_output_name='model_output',\r\n",
        "                          training_output=TrainingOutput(type='Model'))\r\n",
        "# two pipelinedata objects for automl outputs: metrics and the model.\r\n"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987319931
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Change iterations to a reasonable number (50) to get better accuracy\r\n",
        "automl_settings = {\r\n",
        "    \"iteration_timeout_minutes\" : 60,\r\n",
        "    \"iterations\" : 50,\r\n",
        "    \"experiment_timeout_hours\" : 6,\r\n",
        "    \"primary_metric\" : 'AUC_weighted'\r\n",
        "}\r\n",
        "#the run will stop after 50 iterations or 60 minutes, whichever comes first.\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task = 'classification',\r\n",
        "                             path = '.',\r\n",
        "                             debug_log = 'automated_ml_errors.log',\r\n",
        "                             compute_target= compute_target,\r\n",
        "                           #  run_configuration = pipeline_run_config,\r\n",
        "                             featurization = 'auto',\r\n",
        "                             training_data = prepped_train_data,\r\n",
        "                             test_data=prepped_test_data,\r\n",
        "                             label_column_name = 'y',\r\n",
        "                             **automl_settings)\r\n",
        "# debug_log local file if you want to see logs\r\n",
        "\r\n",
        "train_step = AutoMLStep(name='AutoML_Classification',\r\n",
        "    automl_config=automl_config,\r\n",
        "    outputs=[metrics_data,model_data],\r\n",
        "    enable_default_model_output=False,\r\n",
        "    enable_default_metrics_output=False,\r\n",
        "    allow_reuse=True)"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987321937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\r\n",
        "\r\n",
        "# The model name with which to register the trained model in the workspace.\r\n",
        "model_name = PipelineParameter(\"model_name\", default_value=\"AutoML_Classification_Test\")\r\n",
        "\r\n",
        "register_step = PythonScriptStep(\r\n",
        "     name=\"register_model\",\r\n",
        "     script_name=\"register_model.py\",\r\n",
        "     source_directory=\"./Scripts\",\r\n",
        "     allow_reuse=False,\r\n",
        "     arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\r\n",
        "     inputs=[model_data],\r\n",
        "     compute_target=compute_target,\r\n",
        "     runconfig=pipeline_run_config)"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665987323932
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, name= \"automl-classification-E2E_trainingPipeline\")\r\n",
        "\r\n",
        "pipeline = Pipeline(ws, [prep_step, train_step,register_step])\r\n",
        "\r\n",
        "pipeline_run = experiment.submit(pipeline, show_output=True)\r\n",
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Prepare AutoML Classification [2cc1b34b][e7404f40-b146-4bdd-90b0-bd75851b5883], (This step will run and generate new outputs)\nCreated step AutoML_Classification [9912095c][33bf63cf-af35-4a34-861b-1e84c2bb8ced], (This step will run and generate new outputs)Created step register_model [7a87a272][1ed8d80e-6e5e-40d4-bd5c-cace3f57056e], (This step will run and generate new outputs)\n\nSubmitted PipelineRun 68a6296d-a5b7-4dd1-bc30-206745e5bd0a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/68a6296d-a5b7-4dd1-bc30-206745e5bd0a?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRunId: 68a6296d-a5b7-4dd1-bc30-206745e5bd0a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/68a6296d-a5b7-4dd1-bc30-206745e5bd0a?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665986768449
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "                                                    name='classification-training-pipeline',\r\n",
        "                                                    description='Training Pipeline - Classification',\r\n",
        "                                                    version='1.0' \r\n",
        "                                                   )\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipeline_run' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m published_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241m.\u001b[39mpublish_pipeline(\n\u001b[1;32m      2\u001b[0m                                                     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification-training-pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                                     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Pipeline - Classification\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                                     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      5\u001b[0m                                                    )\n\u001b[1;32m      7\u001b[0m published_pipeline\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline_run' is not defined"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666007084865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourceGroups/prodrg/providers/Microsoft.MachineLearningServices/workspaces/prod/PipelineRuns/PipelineSubmit/abe57942-1200-4586-878e-461fe7685551\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665919300124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Schedule,ScheduleRecurrence\r\n",
        "\r\n",
        "weekly=ScheduleRecurrence(frequency='Week',interval=1)\r\n",
        "\r\n",
        "pipeline_schedule=Schedule.create(ws,\r\n",
        "                                name='weekly predictions',\r\n",
        "                                pipeline_id='abe57942-1200-4586-878e-461fe7685551',\r\n",
        "                                #pipeline_id=published_pipeline.id,\r\n",
        "                                experiment_name='test',\r\n",
        "                                recurrence=weekly)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665937820213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pub_pipeline_id=\"abe57942-1200-4586-878e-461fe7685551\"\r\n",
        "schedules = Schedule.list(ws, pipeline_id=pub_pipeline_id)\r\n",
        "\r\n",
        "# We will iterate through the list of schedules and \r\n",
        "# use the last recurrence schedule in the list for further operations: \r\n",
        "print(\"Found these schedules for the pipeline id {}:\".format(pub_pipeline_id))\r\n",
        "for schedule in schedules: \r\n",
        "    print(schedule.id)\r\n",
        "    fetched_schedule = Schedule.get(ws, schedule.id)\r\n",
        "    fetched_schedule.disable(wait_for_provisioning=True)\r\n",
        "    print(\"Disabled schedule {}. New status is: {}\".format(fetched_schedule.id, fetched_schedule.status))\r\n",
        "    #if schedule.recurrence is not None:\r\n",
        "     #   schedule_id = schedule.id\r\n",
        "\r\n",
        "#print(\"Schedule id to be used for schedule operations: {}\".format(schedule_id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found these schedules for the pipeline id abe57942-1200-4586-878e-461fe7685551:\n989204a8-befe-4983-8647-84305fa4d4a7\nProvisioning status: Completed\nDisabled schedule 989204a8-befe-4983-8647-84305fa4d4a7. New status is: Disabled\nf7d6bf8b-7bee-42c5-ba57-6535b6046d26\nProvisioning status: Completed\nDisabled schedule f7d6bf8b-7bee-42c5-ba57-6535b6046d26. New status is: Disabled\n52f8b8d9-0cd2-4b5a-aba3-e78d09d926ba\nProvisioning status: Completed\nDisabled schedule 52f8b8d9-0cd2-4b5a-aba3-e78d09d926ba. New status is: Disabled\n6a665f15-6c55-491c-9c87-d471c8a4e319\nProvisioning status: Completed\nDisabled schedule 6a665f15-6c55-491c-9c87-d471c8a4e319. New status is: Disabled\n9f2160d4-ff82-46e3-9474-fe9d895d7acc\nProvisioning status: Completed\nDisabled schedule 9f2160d4-ff82-46e3-9474-fe9d895d7acc. New status is: Disabled\n6aa7c7eb-6e15-4300-944a-72c87dd9917d\nProvisioning status: Completed\nDisabled schedule 6aa7c7eb-6e15-4300-944a-72c87dd9917d. New status is: Disabled\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665940741191
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use active_only=False to get all schedules including disabled schedules\r\n",
        "schedules = Schedule.list(ws, active_only=True) \r\n",
        "print(\"Your workspace has the following schedules set up:\")\r\n",
        "for schedule in schedules:\r\n",
        "    print(\"{} (Published pipeline: {}\".format(schedule.id, schedule.pipeline_id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Your workspace has the following schedules set up:\n52f8b8d9-0cd2-4b5a-aba3-e78d09d926ba (Published pipeline: abe57942-1200-4586-878e-461fe7685551\n989204a8-befe-4983-8647-84305fa4d4a7 (Published pipeline: abe57942-1200-4586-878e-461fe7685551\n6a665f15-6c55-491c-9c87-d471c8a4e319 (Published pipeline: abe57942-1200-4586-878e-461fe7685551\n9f2160d4-ff82-46e3-9474-fe9d895d7acc (Published pipeline: abe57942-1200-4586-878e-461fe7685551\n6aa7c7eb-6e15-4300-944a-72c87dd9917d (Published pipeline: abe57942-1200-4586-878e-461fe7685551\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665939912240
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fetched_schedule = Schedule.get(ws, schedule_id)\r\n",
        "print(\"Using schedule with id: {}\".format(fetched_schedule.id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using schedule with id: f7d6bf8b-7bee-42c5-ba57-6535b6046d26\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665939917235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the wait_for_provisioning flag to False if you do not want to wait  \r\n",
        "# for the call to provision the schedule in the backend.\r\n",
        "fetched_schedule.disable(wait_for_provisioning=True)\r\n",
        "fetched_schedule = Schedule.get(ws, \"6aa7c7eb-6e15-4300-944a-72c87dd9917d\")\r\n",
        "print(\"Disabled schedule {}. New status is: {}\".format(fetched_schedule.id, fetched_schedule.status))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Provisioning status: Completed\nDisabled schedule 6aa7c7eb-6e15-4300-944a-72c87dd9917d. New status is: Active\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665940440155
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = PublishedPipeline.get(ws, id=\"abe57942-1200-4586-878e-461fe7685551\")\r\n",
        "p.disable()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PublishedPipeline' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mPublishedPipeline\u001b[49m\u001b[38;5;241m.\u001b[39mget(ws, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabe57942-1200-4586-878e-461fe7685551\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m p\u001b[38;5;241m.\u001b[39mdisable()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PublishedPipeline' is not defined"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666007085851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Create the schedule recurrence\r\n",
        "recurrence = ScheduleRecurrence(\r\n",
        "frequency=schedule_frequency,\r\n",
        "interval=schedule_interval,\r\n",
        "week_days=schedule_week_days,\r\n",
        "time_of_day=schedule_time_of_day)\r\n",
        "\r\n",
        "#Create the schedule\r\n",
        "recurring_schedule = Schedule.create(\r\n",
        "ws, name=schedule_name,\r\n",
        "description=schedule_desc,\r\n",
        "pipeline_id=pipeline_id,\r\n",
        "experiment_name=experiment_name,\r\n",
        "recurrence=recurrence)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}