{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#authentication\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ia = InteractiveLoginAuthentication(tenant_id='16b3c013-d300-468d-ac64-7eda0820b6d3')\r\n",
        "\r\n",
        "# You can find tenant id under azure active directory->properties\r\n",
        "ws = Workspace.get(name='Prod',\r\n",
        "                     subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873',\r\n",
        "                     resource_group='ProdRG',auth=ia)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038333522
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute target - you can use different compute targets in different steps in the pipeline\r\n",
        "\r\n",
        "pipeline_cluster = \"Demo-Compute-Cluster\"\r\n",
        "compute_target = ws.compute_targets[pipeline_cluster]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038339515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "data = pd.read_csv(\r\n",
        "    \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\r\n",
        ")\r\n",
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   age          job  marital    education  default housing loan    contact  \\\n0   57   technician  married  high.school       no      no  yes   cellular   \n1   55      unknown  married      unknown  unknown     yes   no  telephone   \n2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n3   36       admin.  married  high.school       no      no   no  telephone   \n4   27    housemaid  married  high.school       no     yes   no   cellular   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         1      failure         -1.8   \n1   may         thu  ...         2    999         0  nonexistent          1.1   \n2   may         fri  ...         1    999         1      failure         -1.8   \n3   jun         fri  ...         4    999         0  nonexistent          1.4   \n4   jul         fri  ...         2    999         0  nonexistent          1.4   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          92.893          -46.2      1.299       5099.1  no  \n1          93.994          -36.4      4.860       5191.0  no  \n2          92.893          -46.2      1.313       5099.1  no  \n3          94.465          -41.8      4.967       5228.1  no  \n4          93.918          -42.7      4.963       5228.1  no  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.299</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>unknown</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>thu</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.860</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.9y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.313</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>4</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.967</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.918</td>\n      <td>-42.7</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038347849
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we will store intermediate data between data preparation step and autoML step in the default datastore of the workspace.\r\n",
        "datastore = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038367813
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "dataset = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    data, target=(datastore, \"dataset\"), name=\"AutoMLE2ETraininggPipeline_Classification_dataset\"\r\n",
        ")\r\n",
        "#I creat dataset from pandas dataframe.\r\n",
        "#Other way: You can create  tabular dataset by using ds=Dataset.Tabular.from_delimited_files(path=xxx) and register it with ds.register()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to dataset/d9276c74-4f62-4ac2-86d6-918c30ef620b/\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038391571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Target: Configure the training run- Environment setup\r\n",
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#env = Environment.get(workspace=ws, name='experiment_env', version='2')\r\n",
        "curated_env=Environment.get(workspace=ws, name='AzureML-sklearn-1.0-ubuntu20.04-py38-cpu')\r\n",
        "pipeline_run_config=RunConfiguration()\r\n",
        "pipeline_run_config.environment=curated_env\r\n",
        "\r\n",
        "# Add conda dependencies to the automl env:\r\n",
        "#pipeline_run_config.environment.python.conda_dependencies = CondaDependencies.create(\r\n",
        " #conda_packages=['pandas'])  "
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038415745
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "#1st way: OutputFileDatasetConfig without giving destination\r\n",
        "#prepped_output_path = OutputFileDatasetConfig(name=\"output_path\") \r\n",
        "# OutputFileDatasetConfig  points a directory and CSV file will be written there. Also given as parameter below.\r\n",
        "# If you do not give destination parameter, it will copy the output to the workspaceblobstore datastore, under the path /dataset/{run-id}/{output-name}. \r\n",
        "# Run-id is the name value on the overview of the job and outputname is the name given as a parameter. In my example, it is output_path.\r\n",
        "\r\n",
        "#2nd way: OutputFileDatasetConfig with giving destination\r\n",
        "output_path = (datastore, f\"azureml/classification_prep_output/\")\r\n",
        "prepped_output_path = OutputFileDatasetConfig(destination = output_path)\r\n",
        "\r\n",
        "input_ds = Dataset.get_by_name(ws, 'AutoMLE2ETraininggPipeline_Classification_dataset')\r\n",
        "\r\n",
        "prep_step=PythonScriptStep(\r\n",
        "    name=\"Prepare AutoML Classification\",\r\n",
        "    script_name=\"prepare.py\",\r\n",
        "    source_directory=\"./Scripts\",\r\n",
        "    arguments=[\"--output_path\",prepped_output_path],\r\n",
        "    inputs=[input_ds.as_named_input('AutoMLE2ETraininggPipeline_Classification_dataset')],\r\n",
        "    compute_target=compute_target,\r\n",
        "    runconfig=pipeline_run_config\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038545926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In an ML pipeline, the input data must be a Dataset object.\r\n",
        "\r\n",
        "prepped_test_data=prepped_output_path.read_delimited_files(\"prepped_train_data_classification.csv\") # This is the test data to send automlstep\r\n",
        "prepped_train_data = prepped_output_path.read_delimited_files(\"prepped_test_data_classification.csv\")\r\n",
        "\r\n",
        "from azureml.pipeline.core import TrainingOutput,PipelineData\r\n",
        "\r\n",
        "metrics_data = PipelineData(name='metrics_data',\r\n",
        "                            datastore=datastore,\r\n",
        "                            pipeline_output_name='metrics_output',\r\n",
        "                            training_output=TrainingOutput(type='Metrics'))\r\n",
        "\r\n",
        "model_data = PipelineData(name='best_model_data',\r\n",
        "                          datastore=datastore,\r\n",
        "                          pipeline_output_name='model_output',\r\n",
        "                          training_output=TrainingOutput(type='Model'))\r\n",
        "# two pipelinedata objects for automl outputs: metrics and the model.\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038550082
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Change iterations to a reasonable number (50) to get better accuracy\r\n",
        "automl_settings = {\r\n",
        "    \"iteration_timeout_minutes\" : 60,\r\n",
        "    \"iterations\" : 50,\r\n",
        "    \"experiment_timeout_hours\" : 6,\r\n",
        "    \"primary_metric\" : 'AUC_weighted'\r\n",
        "}\r\n",
        "#the run will stop after 50 iterations or 60 minutes, whichever comes first.\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task = 'classification',\r\n",
        "                             path = '.',\r\n",
        "                             debug_log = 'automated_ml_errors.log',\r\n",
        "                             compute_target= compute_target,\r\n",
        "                           #  run_configuration = pipeline_run_config,\r\n",
        "                             featurization = 'auto',\r\n",
        "                             training_data = prepped_train_data,\r\n",
        "                             test_data=prepped_test_data,\r\n",
        "                             label_column_name = 'y',\r\n",
        "                             **automl_settings)\r\n",
        "# debug_log local file if you want to see logs\r\n",
        "\r\n",
        "train_step = AutoMLStep(name='AutoML_Classification',\r\n",
        "    automl_config=automl_config,\r\n",
        "    outputs=[metrics_data,model_data],\r\n",
        "    enable_default_model_output=False,\r\n",
        "    enable_default_metrics_output=False,\r\n",
        "    allow_reuse=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038553684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\r\n",
        "\r\n",
        "# The model name with which to register the trained model in the workspace.\r\n",
        "model_name = PipelineParameter(\"model_name\", default_value=\"AutoML_Classification_Test\")\r\n",
        "\r\n",
        "register_step = PythonScriptStep(\r\n",
        "     name=\"register_model\",\r\n",
        "     script_name=\"register_model.py\",\r\n",
        "     source_directory=\"./Scripts\",\r\n",
        "     allow_reuse=False,\r\n",
        "     arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\r\n",
        "     inputs=[model_data],\r\n",
        "     compute_target=compute_target,\r\n",
        "     runconfig=pipeline_run_config)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666038556018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, name= \"automl-classification-E2E_trainingPipeline\")\r\n",
        "\r\n",
        "pipeline = Pipeline(ws, [prep_step, train_step,register_step])\r\n",
        "\r\n",
        "pipeline_run = experiment.submit(pipeline, show_output=True)\r\n",
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Prepare AutoML Classification [b354caf9][2db5abe8-c8cb-4c82-9a47-26411bbe182e], (This step will run and generate new outputs)\nCreated step AutoML_Classification [d8fffa46][57de53a6-6000-40a8-a857-84817049f3da], (This step will run and generate new outputs)\nCreated step register_model [a03833c7][1ed8d80e-6e5e-40d4-bd5c-cace3f57056e], (This step will run and generate new outputs)\nSubmitted PipelineRun 97ec7268-0bf0-48c1-91df-d5c557886f4a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/97ec7268-0bf0-48c1-91df-d5c557886f4a?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRunId: 97ec7268-0bf0-48c1-91df-d5c557886f4a\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/97ec7268-0bf0-48c1-91df-d5c557886f4a?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: c4f83ea4-a7b6-4ed4-9ba1-666860affc03\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/c4f83ea4-a7b6-4ed4-9ba1-666860affc03?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nStepRun( Prepare AutoML Classification ) Status: Running\n\nStepRun(Prepare AutoML Classification) Execution Summary\n=========================================================\nStepRun( Prepare AutoML Classification ) Status: Finished\n{'runId': 'c4f83ea4-a7b6-4ed4-9ba1-666860affc03', 'target': 'Demo-Compute-Cluster', 'status': 'Completed', 'startTimeUtc': '2022-10-17T20:31:43.804243Z', 'endTimeUtc': '2022-10-17T20:32:41.978209Z', 'services': {}, 'properties': {'ContentSnapshotId': 'fedcae8e-558e-4457-8ee6-c8691085cb2d', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '2db5abe8-c8cb-4c82-9a47-26411bbe182e', 'azureml.moduleName': 'Prepare AutoML Classification', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'b354caf9', 'azureml.pipelinerunid': '97ec7268-0bf0-48c1-91df-d5c557886f4a', 'azureml.pipeline': '97ec7268-0bf0-48c1-91df-d5c557886f4a', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'd6af3ea9-af44-49ca-a128-eb419a64e9bb'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'AutoMLE2ETraininggPipeline_Classification_dataset', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '14304791-358a-4c95-b5b3-fb3b5c196122'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'output_c74084d1'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'azureml/classification_prep_output/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"14304791-358a-4c95-b5b3-fb3b5c196122\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='Prod', subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873', resource_group='ProdRG')\"\n  }\n}}], 'runDefinition': {'script': 'prepare.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--output_path', 'DatasetOutputConfig:output_c74084d1'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'Demo-Compute-Cluster', 'dataReferences': {}, 'data': {'AutoMLE2ETraininggPipeline_Classification_dataset': {'dataLocation': {'dataset': {'id': 'd6af3ea9-af44-49ca-a128-eb419a64e9bb', 'name': None, 'version': '4'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'AutoMLE2ETraininggPipeline_Classification_dataset', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'output_c74084d1': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'azureml/classification_prep_output/'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '97ec7268-0bf0-48c1-91df-d5c557886f4a', 'azureml.pipelineRun.moduleNodeId': 'b354caf9', 'azureml.pipelineRun.outputPortName': 'output_c74084d1'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AzureML-sklearn-1.0-ubuntu20.04-py38-cpu', 'version': '30', 'assetId': 'azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/30', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': None, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': \"FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220902.v1\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/sklearn-1.0\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.8 pip=21.3.1 -c anaconda -c conda-forge\\n\\n# Prepend path to AzureML conda environment\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\n# Install pip dependencies\\nRUN pip install 'matplotlib~=3.5.0' \\\\\\n                'psutil~=5.8.0' \\\\\\n                'tqdm~=4.62.0' \\\\\\n                'pandas~=1.3.0' \\\\\\n                'scipy~=1.7.0' \\\\\\n                'numpy~=1.21.0' \\\\\\n                'ipykernel~=6.0' \\\\\\n                'azureml-core==1.45.0' \\\\\\n                'azureml-defaults==1.45.0' \\\\\\n                'azureml-mlflow==1.45.0' \\\\\\n                'azureml-telemetry==1.45.0' \\\\\\n                'scikit-learn~=1.0.0'\\n\\n# This is needed for mpi to locate libpython\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\n\", 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/rslex.log.2022-10-17-20': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/logs/azureml/dataprep/0/rslex.log.2022-10-17-20?sv=2019-07-07&sr=b&sig=MDfN3r9%2Fo4YZ3McCWCgXJytgso6qn5mJgiI1YV2Joog%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A39Z&se=2022-10-18T04%3A32%3A39Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=baBJkbdrQ2mPv7pzBtZ2Ogbj25d2VXs5UU66gP1DQNk%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A39Z&se=2022-10-18T04%3A32%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=htp36GD5Z50y%2Bu2NIOoLi5oPWRiOVmtMsMB1sBMQ42o%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A39Z&se=2022-10-18T04%3A32%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Y9L2dp3oKpUr785YvvO55lw9jRMBkddwylcq1LanOwg%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A39Z&se=2022-10-18T04%3A32%3A39Z&sp=r', 'user_logs/std_log.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=GjPXOxvyLdqRCVhYzS0uv8QhBYQpuiWTVpvn6A2xa4k%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=FoE232g1%2FRFdXgvyKWh4kU7LFvbNXkKhqvLjSa7G5Tw%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=uCTdpGX7o9B72M7VnL%2BA8TdPF8xt1FCNgLxUb5z5KcQ%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/data_capability/rslex.log.2022-10-17-20': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/data_capability/rslex.log.2022-10-17-20?sv=2019-07-07&sr=b&sig=8Cx9LBxD%2FlnviGKdGHKUEzDxFJ6Js6RYWvKc%2FNmyCKw%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=JUwrLoLgPGHAH2YiCoFNQr1WR1NxtGuoEU5RahV7EoA%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=9qyxazYPv9Ly4lBvMPtaNF0YaSRckUJTNIlMzsKasfE%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=nGjHJaQPeBIEc%2FrzmBDCJ6WWpZxZ5zljt28YObdxrAE%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=XPDZFprXkoe8C8yc28CtVIF6lITVz7rBFHF9FcDH5tQ%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.c4f83ea4-a7b6-4ed4-9ba1-666860affc03/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=mgZzhMOiwcQDY5s0VdNFqBIjqvuTogWARFRbOw%2BiJFY%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-17T20%3A19%3A32Z&ske=2022-10-19T04%3A29%3A32Z&sks=b&skv=2019-07-07&st=2022-10-17T20%3A22%3A43Z&se=2022-10-18T04%3A32%3A43Z&sp=r'}, 'submittedBy': 'Yeliz Kilinc'}\n\n\n\n\nStepRunId: c789bfca-0fa1-4b66-805b-8b2ac6a556bd\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/c789bfca-0fa1-4b66-805b-8b2ac6a556bd?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nStepRun( AutoML_Classification ) Status: NotStarted\nStepRun( AutoML_Classification ) Status: Running\n\nStepRun(AutoML_Classification) Execution Summary\n=================================================\nStepRun( AutoML_Classification ) Status: Finished\n\nWarnings:\nNo scores improved over last 10 iterations, so experiment stopped early. This early stopping behavior can be disabled by setting enable_early_stopping = False in AutoMLConfig for notebook/python SDK runs.\n"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'savedId'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(ws, [prep_step, train_step,register_step])\n\u001b[1;32m      8\u001b[0m pipeline_run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(pipeline, show_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:738\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    744\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:833\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m--> 833\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_details\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_lineage.py:43\u001b[0m, in \u001b[0;36m_InputDatasetsLineage.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_lineage.py:40\u001b[0m, in \u001b[0;36m_InputDatasetsLineage.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_lineage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_lineage.py:50\u001b[0m, in \u001b[0;36m_InputDatasetsLineage._resolve_lineage\u001b[0;34m(self, instantiate)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_lineage\u001b[39m(\u001b[38;5;28mself\u001b[39m, instantiate):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_input_dataset(ds, instantiate) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_datasets]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_lineage.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_lineage\u001b[39m(\u001b[38;5;28mself\u001b[39m, instantiate):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_input_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_datasets]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_lineage.py:53\u001b[0m, in \u001b[0;36m_InputDatasetsLineage._resolve_input_dataset\u001b[0;34m(self, dataset_info, instantiate)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_input_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_info, instantiate):\n\u001b[0;32m---> 53\u001b[0m     saved_id \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midentifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msavedId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     54\u001b[0m     resolved \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: saved_id\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m         }\n\u001b[1;32m     61\u001b[0m     }\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instantiate:\n",
            "\u001b[0;31mKeyError\u001b[0m: 'savedId'"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666040731685
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "                                                    name='Centrica-Workshop-Training-Pipeline',\r\n",
        "                                                    description='Training Pipeline - Classification',\r\n",
        "                                                    version='1.0' \r\n",
        "                                                   )\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "Pipeline(Name: Centrica-Workshop-Training-Pipeline,\nId: 1a8bf1f2-e7f3-40d8-bdb7-070df45cfa68,\nStatus: Active,\nEndpoint: https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourceGroups/ProdRG/providers/Microsoft.MachineLearningServices/workspaces/Prod/PipelineRuns/PipelineSubmit/1a8bf1f2-e7f3-40d8-bdb7-070df45cfa68)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Centrica-Workshop-Training-Pipeline</td><td><a href=\"https://ml.azure.com/pipelines/1a8bf1f2-e7f3-40d8-bdb7-070df45cfa68?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/ProdRG/workspaces/Prod\" target=\"_blank\" rel=\"noopener\">1a8bf1f2-e7f3-40d8-bdb7-070df45cfa68</a></td><td>Active</td><td><a href=\"https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourceGroups/ProdRG/providers/Microsoft.MachineLearningServices/workspaces/Prod/PipelineRuns/PipelineSubmit/1a8bf1f2-e7f3-40d8-bdb7-070df45cfa68\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041369965
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourceGroups/ProdRG/providers/Microsoft.MachineLearningServices/workspaces/Prod/PipelineRuns/PipelineSubmit/0f37f225-e312-4e62-a79b-5896bf9a5c0c\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041244000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Schedule,ScheduleRecurrence"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041251694
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use active_only=False to get all schedules including disabled schedules\r\n",
        "schedules = Schedule.list(ws, active_only=True) \r\n",
        "print(\"Your workspace has the following schedules set up:\")\r\n",
        "for schedule in schedules:\r\n",
        "    print(\"{} (Published pipeline: {}\".format(schedule.id, schedule.pipeline_id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Your workspace has the following schedules set up:\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041257623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weekly=ScheduleRecurrence(frequency='Week',interval=1)\r\n",
        "\r\n",
        "pipeline_schedule=Schedule.create(ws,\r\n",
        "                                name='weekly predictions',\r\n",
        "                                pipeline_id=published_pipeline.id,\r\n",
        "                                experiment_name='test',\r\n",
        "                                recurrence=weekly)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041267619
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedules = Schedule.list(ws, pipeline_id=published_pipeline.id)\r\n",
        "\r\n",
        "# We will iterate through the list of schedules and disable\r\n",
        "print(\"Found these schedules for the pipeline id {}:\".format(published_pipeline.id))\r\n",
        "for schedule in schedules: \r\n",
        "    print(schedule.id)\r\n",
        "    fetched_schedule = Schedule.get(ws, schedule.id)\r\n",
        "    fetched_schedule.disable(wait_for_provisioning=True)\r\n",
        "    print(\"Disabled schedule {}. New status is: {}\".format(fetched_schedule.id, fetched_schedule.status))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found these schedules for the pipeline id 0f37f225-e312-4e62-a79b-5896bf9a5c0c:\nb468f29d-0d95-4882-a07b-97bbb5eb7951\nProvisioning status: Completed\nDisabled schedule b468f29d-0d95-4882-a07b-97bbb5eb7951. New status is: Disabled\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041309604
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = published_pipeline.get(ws, id=published_pipeline.id)\r\n",
        "p.disable()"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666041377594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''#Create the schedule recurrence\r\n",
        "recurrence = ScheduleRecurrence(\r\n",
        "frequency=schedule_frequency,\r\n",
        "interval=schedule_interval,\r\n",
        "week_days=schedule_week_days,\r\n",
        "time_of_day=schedule_time_of_day)\r\n",
        "\r\n",
        "#Create the schedule\r\n",
        "recurring_schedule = Schedule.create(\r\n",
        "ws, name=schedule_name,\r\n",
        "description=schedule_desc,\r\n",
        "pipeline_id=pipeline_id,\r\n",
        "experiment_name=experiment_name,\r\n",
        "recurrence=recurrence)'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}