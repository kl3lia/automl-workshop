{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.train.automl import AutoMLConfig"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665914231163
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665914237094
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute target - you can use different compute targets in different steps in the pipeline\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "pipeline_cluster = \"Demo-Compute-Cluster\"\r\n",
        "compute_target = ws.compute_targets[pipeline_cluster]"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665915084208
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "data = pd.read_csv(\r\n",
        "    \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\r\n",
        ")\r\n",
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "   age          job  marital    education  default housing loan    contact  \\\n0   57   technician  married  high.school       no      no  yes   cellular   \n1   55      unknown  married      unknown  unknown     yes   no  telephone   \n2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n3   36       admin.  married  high.school       no      no   no  telephone   \n4   27    housemaid  married  high.school       no     yes   no   cellular   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         1      failure         -1.8   \n1   may         thu  ...         2    999         0  nonexistent          1.1   \n2   may         fri  ...         1    999         1      failure         -1.8   \n3   jun         fri  ...         4    999         0  nonexistent          1.4   \n4   jul         fri  ...         2    999         0  nonexistent          1.4   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          92.893          -46.2      1.299       5099.1  no  \n1          93.994          -36.4      4.860       5191.0  no  \n2          92.893          -46.2      1.313       5099.1  no  \n3          94.465          -41.8      4.967       5228.1  no  \n4          93.918          -42.7      4.963       5228.1  no  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.299</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>unknown</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>thu</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.860</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.9y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.313</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>4</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.967</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.918</td>\n      <td>-42.7</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665915090079
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we will store intermediate data between data preparation step and autoML step in the default datastore of the workspace.\r\n",
        "datastore = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665915213004
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "dataset = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    data, target=(datastore, \"dataset/\"), name=\"AutoMLE2ETraininggPipeline_Classification_dataset\"\r\n",
        ")\r\n",
        "#I creat dataset from pandas dataframe.\r\n",
        "#Other way: You can create  tabular dataset by using ds=Dataset.Tabular.from_delimited_files(path=xxx) and register it with ds.register()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to dataset//b4890d23-2d45-4c4e-936f-93d606e4f5f2/\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665915351188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Target: Configure the training run- Environment setup\r\n",
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#env = Environment.get(workspace=ws, name='experiment_env', version='2')\r\n",
        "curated_env=Environment.get(workspace=ws, name='AzureML-sklearn-1.0-ubuntu20.04-py38-cpu')\r\n",
        "pipeline_run_config=RunConfiguration()\r\n",
        "pipeline_run_config.environment=curated_env\r\n",
        "\r\n",
        "# Add conda dependencies to the automl env:\r\n",
        "#pipeline_run_config.environment.python.conda_dependencies = CondaDependencies.create(\r\n",
        " #conda_packages=['pandas'])  "
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665915469051
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "#1st way: OutputFileDatasetConfig without giving destination\r\n",
        "#prepped_output_path = OutputFileDatasetConfig(name=\"output_path\") \r\n",
        "# OutputFileDatasetConfig  points a directory and CSV file will be written there. Also given as parameter below.\r\n",
        "# If you do not give destination parameter, it will copy the output to the workspaceblobstore datastore, under the path /dataset/{run-id}/{output-name}. \r\n",
        "# Run-id is the name value on the overview of the job and outputname is the name given as a parameter. In my example, it is output_path.\r\n",
        "\r\n",
        "#2nd way: OutputFileDatasetConfig with giving destination\r\n",
        "output_path = (datastore, f\"azureml/classification_prep_output/\")\r\n",
        "prepped_output_path = OutputFileDatasetConfig(destination = output_path)\r\n",
        "\r\n",
        "input_ds = Dataset.get_by_name(ws, 'AutoMLE2ETraininggPipeline_Classification_dataset')\r\n",
        "\r\n",
        "prep_step=PythonScriptStep(\r\n",
        "    name=\"Prepare AutoML Classification\",\r\n",
        "    script_name=\"prepare.py\",\r\n",
        "    source_directory=\"./Scripts\",\r\n",
        "    #arguments=['--input-data',input_ds.as_named_input('AutoMLE2ETraininggPipeline_Classification_dataset'),'--prepped-data',output],\r\n",
        "    arguments=[\"--output_path\",prepped_output_path],\r\n",
        "    inputs=[input_ds.as_named_input('AutoMLE2ETraininggPipeline_Classification_dataset')],\r\n",
        "    compute_target=compute_target,\r\n",
        "    runconfig=pipeline_run_config\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665916070043
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In an ML pipeline, the input data must be a Dataset object.\r\n",
        "\r\n",
        "prepped_test_data=prepped_output_path.read_delimited_files(\"prepped_train_data_classification.csv\") # This is the test data to send automlstep\r\n",
        "prepped_train_data = prepped_output_path.read_delimited_files(\"prepped_test_data_classification.csv\")\r\n",
        "\r\n",
        "from azureml.pipeline.core import TrainingOutput,PipelineData\r\n",
        "\r\n",
        "metrics_data = PipelineData(name='metrics_data',\r\n",
        "                            datastore=datastore,\r\n",
        "                            pipeline_output_name='metrics_output',\r\n",
        "                            training_output=TrainingOutput(type='Metrics'))\r\n",
        "\r\n",
        "model_data = PipelineData(name='best_model_data',\r\n",
        "                          datastore=datastore,\r\n",
        "                          pipeline_output_name='model_output',\r\n",
        "                          training_output=TrainingOutput(type='Model'))\r\n",
        "# two pipelinedata objects for automl outputs: metrics and the model.\r\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665916208121
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Change iterations to a reasonable number (50) to get better accuracy\r\n",
        "automl_settings = {\r\n",
        "    \"iteration_timeout_minutes\" : 60,\r\n",
        "    \"iterations\" : 50,\r\n",
        "    \"experiment_timeout_hours\" : 0.25,\r\n",
        "    \"primary_metric\" : 'AUC_weighted'\r\n",
        "}\r\n",
        "#the run will stop after 50 iterations or 60 minutes, whichever comes first.\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task = 'classification',\r\n",
        "                             path = '.',\r\n",
        "                             debug_log = 'automated_ml_errors.log',\r\n",
        "                             compute_target= compute_target,\r\n",
        "                           #  run_configuration = pipeline_run_config,\r\n",
        "                             featurization = 'auto',\r\n",
        "                             training_data = prepped_train_data,\r\n",
        "                             test_data=prepped_test_data,\r\n",
        "                             label_column_name = 'y',\r\n",
        "                             **automl_settings)\r\n",
        "# debug_log local file if you want to see logs\r\n",
        "\r\n",
        "train_step = AutoMLStep(name='AutoML_Classification',\r\n",
        "    automl_config=automl_config,\r\n",
        "    outputs=[metrics_data,model_data],\r\n",
        "    enable_default_model_output=False,\r\n",
        "    enable_default_metrics_output=False,\r\n",
        "    allow_reuse=True)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665916249109
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\r\n",
        "\r\n",
        "# The model name with which to register the trained model in the workspace.\r\n",
        "model_name = PipelineParameter(\"model_name\", default_value=\"AutoML_Classification_Test\")\r\n",
        "\r\n",
        "register_step = PythonScriptStep(\r\n",
        "     name=\"register_model\",\r\n",
        "     script_name=\"register_model.py\",\r\n",
        "     source_directory=\"./Scripts\",\r\n",
        "     allow_reuse=False,\r\n",
        "     arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\r\n",
        "     inputs=[model_data],\r\n",
        "     compute_target=compute_target,\r\n",
        "     runconfig=pipeline_run_config)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665916269116
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, name= \"automl-classification-E2E_trainingPipeline\")\r\n",
        "\r\n",
        "pipeline = Pipeline(ws, [prep_step, train_step,register_step])\r\n",
        "pipeline_run = experiment.submit(pipeline, show_output=True)\r\n",
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Prepare AutoML Classification [0bbb7aaf][a8d69bec-5c27-48fe-86b6-08a4cf138e36], (This step will run and generate new outputs)\nCreated step AutoML_Classification [adc180b9][bc45f149-84d4-46db-99b5-65b6f11deec1], (This step will run and generate new outputs)\nCreated step register_model [9e09f6a7][1ed8d80e-6e5e-40d4-bd5c-cace3f57056e], (This step will run and generate new outputs)\nSubmitted PipelineRun 71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRunId: 71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 0f091ee2-2b98-40de-b2b9-264401c351da\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/0f091ee2-2b98-40de-b2b9-264401c351da?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nStepRun( Prepare AutoML Classification ) Status: Running\n\nStepRun(Prepare AutoML Classification) Execution Summary\n=========================================================\nStepRun( Prepare AutoML Classification ) Status: Finished\n{'runId': '0f091ee2-2b98-40de-b2b9-264401c351da', 'target': 'Demo-Compute-Cluster', 'status': 'Completed', 'startTimeUtc': '2022-10-16T10:53:25.329267Z', 'endTimeUtc': '2022-10-16T10:54:25.375021Z', 'services': {}, 'properties': {'ContentSnapshotId': 'ef4f37bf-c597-448a-8455-ff6a5a7cceb6', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'a8d69bec-5c27-48fe-86b6-08a4cf138e36', 'azureml.moduleName': 'Prepare AutoML Classification', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '0bbb7aaf', 'azureml.pipelinerunid': '71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1', 'azureml.pipeline': '71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '4166e359-a311-4c81-8700-6415e0af558f'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'AutoMLE2ETraininggPipeline_Classification_dataset', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '96cf8ffc-4dd5-4e31-bd03-838efa602864'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'output_ce6ea4e2'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'azureml/classification_prep_output/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"96cf8ffc-4dd5-4e31-bd03-838efa602864\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='prod', subscription_id='fe38c376-b42a-4741-9e7c-f5d7c31e5873', resource_group='prodrg')\"\n  }\n}}], 'runDefinition': {'script': 'prepare.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--output_path', 'DatasetOutputConfig:output_ce6ea4e2'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'Demo-Compute-Cluster', 'dataReferences': {}, 'data': {'AutoMLE2ETraininggPipeline_Classification_dataset': {'dataLocation': {'dataset': {'id': '4166e359-a311-4c81-8700-6415e0af558f', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'AutoMLE2ETraininggPipeline_Classification_dataset', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'output_ce6ea4e2': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'azureml/classification_prep_output/'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '71cf7b6e-cc9e-4fa4-b0dc-bab77101d2d1', 'azureml.pipelineRun.moduleNodeId': '0bbb7aaf', 'azureml.pipelineRun.outputPortName': 'output_ce6ea4e2'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AzureML-sklearn-1.0-ubuntu20.04-py38-cpu', 'version': '30', 'assetId': 'azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/30', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': None, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': \"FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220902.v1\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/sklearn-1.0\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.8 pip=21.3.1 -c anaconda -c conda-forge\\n\\n# Prepend path to AzureML conda environment\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\n# Install pip dependencies\\nRUN pip install 'matplotlib~=3.5.0' \\\\\\n                'psutil~=5.8.0' \\\\\\n                'tqdm~=4.62.0' \\\\\\n                'pandas~=1.3.0' \\\\\\n                'scipy~=1.7.0' \\\\\\n                'numpy~=1.21.0' \\\\\\n                'ipykernel~=6.0' \\\\\\n                'azureml-core==1.45.0' \\\\\\n                'azureml-defaults==1.45.0' \\\\\\n                'azureml-mlflow==1.45.0' \\\\\\n                'azureml-telemetry==1.45.0' \\\\\\n                'scikit-learn~=1.0.0'\\n\\n# This is needed for mpi to locate libpython\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\n\", 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/rslex.log.2022-10-16-10': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/logs/azureml/dataprep/0/rslex.log.2022-10-16-10?sv=2019-07-07&sr=b&sig=8b9vwvcn3%2Bcl1N31k%2FWQHpVMz14RZziqB3KSu%2F5UDi0%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A23Z&se=2022-10-16T18%3A54%3A23Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=lsmwwT7M%2BQkf84wAczRGzDFRtDo8QxuZa%2FfQqjhWhXQ%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A23Z&se=2022-10-16T18%3A54%3A23Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=cOxj7N8L7kk9Z7f0Fd9gWH5Pmfba6ffkxbqAFe2g15w%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A23Z&se=2022-10-16T18%3A54%3A23Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=JfVm6u81jVqOD%2Fo%2FNp9eaN5iEnPZ5aA4veeynzd2IFA%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A23Z&se=2022-10-16T18%3A54%3A23Z&sp=r', 'user_logs/std_log.txt': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=77bMHVXoJVJ9vdblon5XR9c8W5l8qX%2FPCbSnYA0eX%2F8%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A26Z&se=2022-10-16T18%3A54%3A26Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=dR8xwynn92E8Pf5nCpJZW4LY0c8N53HjqGjYb6i%2BX6I%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=a7leHcfCgo5yfQdMfzAPy249aby2XcH3DQ%2Bn8U%2BzPWQ%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/data_capability/rslex.log.2022-10-16-10': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/data_capability/rslex.log.2022-10-16-10?sv=2019-07-07&sr=b&sig=Rnt4y%2FdjdPCdE%2FKyU0lJGGpRtF%2B6wCwH3qi2VmZ6MyM%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=KJkP1CVPipjQR26a%2BYO%2BjnUdTThul4CQtfB%2FOge%2BLhI%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=o4kaMHCsoF2nfhTqx%2F5yDlvtn0TBwexpaZrBrq%2FK9NY%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=Ys1h4mB9RAmr7TQVHe8%2FmpWXjrZ%2BYZMt2ZclTElWQ74%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=sIWsiCmPr%2FqBUTIe%2F2EZgn2Nbg1poPabmg1lfWXAna4%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://prod0117660760.blob.core.windows.net/azureml/ExperimentRun/dcid.0f091ee2-2b98-40de-b2b9-264401c351da/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=RFBnXBp71Pn1Z12mJ2MZ9a69%2FgDtYA2lsmdzsV5rTLA%3D&skoid=b858771d-9924-4dd3-b292-4a944e9f3321&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2022-10-16T10%3A21%3A31Z&ske=2022-10-17T18%3A31%3A31Z&sks=b&skv=2019-07-07&st=2022-10-16T10%3A44%3A27Z&se=2022-10-16T18%3A54%3A27Z&sp=r'}, 'submittedBy': 'Yeliz Kilinc'}\n\n\n\n\nStepRunId: 3e6bbc34-e215-4664-a809-5d6814058695\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/3e6bbc34-e215-4664-a809-5d6814058695?wsid=/subscriptions/fe38c376-b42a-4741-9e7c-f5d7c31e5873/resourcegroups/prodrg/workspaces/prod&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\nStepRun( AutoML_Classification ) Status: NotStarted\nStepRun( AutoML_Classification ) Status: Running\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1665916478182
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Schedule,ScheduleRecurrence\r\n",
        "\r\n",
        "weekly=ScheduleRecurrence(frequency='Week',interval=1)\r\n",
        "pipeline_schedule=Schedule.create(ws,\r\n",
        "name='weekly predictions',\r\n",
        "pipeline_id=published_pipeline.id,\r\n",
        "experiment_name='Batch_predictions',\r\n",
        "recurrence=weekly)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}